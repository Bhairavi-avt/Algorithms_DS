{
  "cells": [
    {
      "cell_type": "code",
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2025-03-03T22:15:06.501368Z",
          "start_time": "2025-03-03T22:15:06.499137Z"
        },
        "id": "initial_id"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Concatenate, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-03T22:15:06.725230Z",
          "start_time": "2025-03-03T22:15:06.721940Z"
        },
        "id": "d5b8a4f7ffca5b9a"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Concatenate, Flatten\n",
        "\n",
        "# Define function to create the neural network model\n",
        "def create_nn_model(vocab_size: int, embedding_dim: int, max_length: int, num_of_dense: int, output_dim: int) -> Model:\n",
        "    \"\"\"\n",
        "    Creates a neural network model that processes user prompts using an embedding layer,\n",
        "    concatenates it with function ratings, and passes through dense layers.\n",
        "\n",
        "    Args:\n",
        "        vocab_size (int): Size of the vocabulary for embedding.\n",
        "        embedding_dim (int): Dimensionality of the embedding layer.\n",
        "        max_length (int): Maximum length of input sequences.\n",
        "        num_of_dense (int): Number of dense layers before concatenation.\n",
        "\n",
        "    Returns:\n",
        "        Model: A compiled TensorFlow model.\n",
        "    \"\"\"\n",
        "    # Text input (user prompt)\n",
        "    text_input = Input(shape=(max_length,), name=\"text_input\")\n",
        "    embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length)(text_input)\n",
        "    flatten = Flatten()(embedding)\n",
        "\n",
        "    # Dense layers for text input\n",
        "    num_neurons = 2**12  # Start with 4096 neurons\n",
        "    x = flatten\n",
        "    for _ in range(num_of_dense):\n",
        "        num_neurons = max(1, int(num_neurons / 2))  # Ensure integer neurons, minimum of 1\n",
        "        x = Dense(num_neurons, activation='relu')(x)\n",
        "\n",
        "    # Numeric input (func_rating)\n",
        "    func_rating_input = Input(shape=(1,), name=\"func_rating_input\")\n",
        "    y = Dense(32, activation='relu')(func_rating_input)\n",
        "\n",
        "    # Concatenate both paths\n",
        "    concatenated = Concatenate()([x, y])\n",
        "    # output = Dense(1, activation='linear', name=\"output\")(concatenated)\n",
        "    output = Dense(output_dim, activation='softmax', name=\"output\")(concatenated)\n",
        "\n",
        "    # Define and compile the model\n",
        "    model = Model(inputs=[text_input, func_rating_input], outputs=output)\n",
        "\n",
        "    # Set up learning rate scheduler\n",
        "    # code here:\n",
        "\n",
        "    # Compile\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "id": "d5b8a4f7ffca5b9a",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-03T22:15:06.908382Z",
          "start_time": "2025-03-03T22:15:06.906556Z"
        },
        "id": "e147c35695592867"
      },
      "cell_type": "code",
      "source": [
        "from repo_extractor import result_df\n",
        "\n",
        "df = result_df"
      ],
      "id": "e147c35695592867",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-03T22:15:07.085791Z",
          "start_time": "2025-03-03T22:15:07.082955Z"
        },
        "id": "525eaedfd0b0e33e",
        "outputId": "204446fc-3d73-4300-ba48-b90950f840be"
      },
      "cell_type": "code",
      "source": [
        "df[\"custom_rating\"].unique()"
      ],
      "id": "525eaedfd0b0e33e",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3, 4, 2, 5, 1, 0])"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-03T22:15:07.271147Z",
          "start_time": "2025-03-03T22:15:07.269256Z"
        },
        "id": "fd883a76ebca6026",
        "outputId": "139b8ca1-7b97-4bee-a1a6-f51210d8c0e8"
      },
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "id": "fd883a76ebca6026",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(322, 4)"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-03T22:15:07.441223Z",
          "start_time": "2025-03-03T22:15:07.432210Z"
        },
        "id": "8fc2908325e253ce",
        "outputId": "c60ceeea-72b8-439f-ea6c-1f60c433804c"
      },
      "cell_type": "code",
      "source": [
        "# Tokenize and prepare data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df[\"user_prompt\"])\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Calculates the size of the vocabulary\n",
        "\n",
        "# Ensuring the vocab_size is large enough for all indices\n",
        "max_index = max([max(seq) if seq else 0 for seq in tokenizer.texts_to_sequences(df[\"user_prompt\"])])\n",
        "if max_index >= vocab_size:\n",
        "    vocab_size = max_index + 1\n",
        "\n",
        "print(f\"Adjusted vocab_size: {vocab_size}\")\n",
        "\n",
        "# Determine the maximum length of sequences\n",
        "max_length = max([len(x.split()) for x in df[\"user_prompt\"]])\n",
        "embedding_dim = 8  # You can adjust this dimension based on your model complexity and dataset\n",
        "\n",
        "# Convert text data into sequences\n",
        "X_text = tokenizer.texts_to_sequences(df[\"user_prompt\"])\n",
        "X_text = pad_sequences(X_text, maxlen=max_length, padding='post')\n",
        "print(X_text.shape)  # This will print the shape of your padded sequence array\n",
        "\n",
        "# Numeric input\n",
        "X_func_rating = np.array(df[\"func_rating\"]).reshape(-1, 1)\n",
        "print(X_func_rating.shape)  # This will print the shape of your function rating array\n",
        "\n",
        "# Target variable\n",
        "y = np.array(df[\"custom_rating\"]).reshape(-1, 1)\n",
        "print(y.shape)  # This will print the shape of your target variable array"
      ],
      "id": "8fc2908325e253ce",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusted vocab_size: 908\n",
            "(322, 26)\n",
            "(322, 1)\n",
            "(322, 1)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-03T22:15:07.804140Z",
          "start_time": "2025-03-03T22:15:07.623525Z"
        },
        "id": "fb21238d1e7e6877",
        "outputId": "2d032103-cc7b-4d1c-aa28-5e9019b24036"
      },
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, TFBertModel\n",
        "import tensorflow as tf\n",
        "\n",
        "# Initialize the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize and prepare data for BERT\n",
        "def prepare_data(texts):\n",
        "    \"\"\"\n",
        "    Prepares input text data into tokenized tensors for BERT.\n",
        "\n",
        "    Args:\n",
        "    texts (pd.Series): A pandas series containing text entries.\n",
        "\n",
        "    Returns:\n",
        "    tf.Tensor: Tokenized and formatted input for BERT.\n",
        "    \"\"\"\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in texts:\n",
        "        encoded = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=512, # Can adjust depending on your specific needs\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='tf',\n",
        "        )\n",
        "        input_ids.append(encoded['input_ids'])\n",
        "        attention_masks.append(encoded['attention_mask'])\n",
        "\n",
        "    input_ids = tf.concat(input_ids, axis=0)\n",
        "    attention_masks = tf.concat(attention_masks, axis=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "# Example usage\n",
        "X_text, X_mask = prepare_data(df[\"user_prompt\"])\n",
        "\n",
        "print(X_text.shape)  # This will show the shape of your input_ids\n",
        "print(X_mask.shape)  # This will show the shape of your attention masks"
      ],
      "id": "fb21238d1e7e6877",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(322, 512)\n",
            "(322, 512)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-03T22:15:08.610972Z",
          "start_time": "2025-03-03T22:15:08.608336Z"
        },
        "id": "6a6173679afcdc91",
        "outputId": "5fe6d3f9-809a-4876-cad5-ee764d997c94"
      },
      "cell_type": "code",
      "source": [
        "print(X_mask)"
      ],
      "id": "6a6173679afcdc91",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1 1 1 ... 0 0 0]\n",
            " [1 1 1 ... 0 0 0]\n",
            " [1 1 1 ... 0 0 0]\n",
            " ...\n",
            " [1 1 1 ... 0 0 0]\n",
            " [1 1 1 ... 0 0 0]\n",
            " [1 1 1 ... 0 0 0]], shape=(322, 512), dtype=int32)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-03T22:15:11.376343Z",
          "start_time": "2025-03-03T22:15:11.373150Z"
        },
        "id": "b18b9485ffff6108",
        "outputId": "68da42be-0ef5-4bdd-c5e2-72386b12fc55"
      },
      "cell_type": "code",
      "source": [
        "df[\"custom_rating\"].unique()"
      ],
      "id": "b18b9485ffff6108",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3, 4, 2, 5, 1, 0])"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-03T22:15:12.535814Z",
          "start_time": "2025-03-03T22:15:12.533290Z"
        },
        "id": "f97e552800a59e2e",
        "outputId": "db115c4e-63d0-4f42-ce8a-7c402b1b6a9f"
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# Assuming y is your array of class labels shaped as (20, 1)\n",
        "# Convert labels to one-hot encoding\n",
        "y_one_hot = to_categorical(y > 3)\n",
        "\n",
        "# Check the new shape of y_one_hot\n",
        "print(y_one_hot.shape)"
      ],
      "id": "f97e552800a59e2e",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(322, 2)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-03T22:15:13.136615Z",
          "start_time": "2025-03-03T22:15:13.122590Z"
        },
        "id": "fa19b9564abd98dd",
        "outputId": "bd4725ab-9c7c-4205-9936-79ac671da441"
      },
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "num_of_dense_layers = 2  # Example: 2 dense layers before concatenation\n",
        "model = create_nn_model(vocab_size, embedding_dim, max_length, num_of_dense_layers, 2)"
      ],
      "id": "fa19b9564abd98dd",
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/searchbot-001/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-03T22:15:13.730266Z",
          "start_time": "2025-03-03T22:15:13.616510Z"
        },
        "id": "1e45cfd8ed7dd41f",
        "outputId": "84caaa22-4b74-4105-f8e8-25bd6845e8f0"
      },
      "cell_type": "code",
      "source": [
        "# Example of setting parameters based on your dataset\n",
        "vocab_size = len(tokenizer.vocab)  # Using the BERT tokenizer's vocabulary size\n",
        "print(f\"vocab_size: {vocab_size}\")\n",
        "embedding_dim = 100  # Example dimensionality\n",
        "max_length = 512  # From your output, each input sequence length\n",
        "num_of_dense = 10  # Example of using three dense layers\n",
        "output_dim = 2  # Number of output classes, change this as per your specific task\n",
        "\n",
        "# Initialize the model with the parameters\n",
        "model = create_nn_model(vocab_size=vocab_size, embedding_dim=embedding_dim, max_length=max_length, num_of_dense=num_of_dense, output_dim=output_dim)"
      ],
      "id": "1e45cfd8ed7dd41f",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocab_size: 30522\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/searchbot-001/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-04T10:51:41.243105Z",
          "start_time": "2025-03-04T00:41:23.366612Z"
        },
        "id": "6b73ef4b79738b5e",
        "outputId": "05c80a99-2913-4cd2-9bfd-32c73021dd4b"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    {\"text_input\": X_text, \"func_rating_input\": X_func_rating},\n",
        "    y_one_hot,\n",
        "    epochs=2000,\n",
        "    batch_size=5,\n",
        "    validation_split=0.05,\n",
        "    verbose=2\n",
        ")"
      ],
      "id": "6b73ef4b79738b5e",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4845 - val_accuracy: 0.8824 - val_loss: 0.5048\n",
            "Epoch 2/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.4952\n",
            "Epoch 3/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.5024\n",
            "Epoch 4/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7639 - loss: 0.4853 - val_accuracy: 0.8824 - val_loss: 0.4967\n",
            "Epoch 5/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4846 - val_accuracy: 0.8824 - val_loss: 0.5172\n",
            "Epoch 6/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4849 - val_accuracy: 0.8824 - val_loss: 0.5427\n",
            "Epoch 7/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4857 - val_accuracy: 0.8824 - val_loss: 0.5119\n",
            "Epoch 8/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4862 - val_accuracy: 0.8824 - val_loss: 0.4965\n",
            "Epoch 9/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7672 - loss: 0.4863 - val_accuracy: 0.8824 - val_loss: 0.4969\n",
            "Epoch 10/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4836 - val_accuracy: 0.8824 - val_loss: 0.5020\n",
            "Epoch 11/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4817 - val_accuracy: 0.8824 - val_loss: 0.5205\n",
            "Epoch 12/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.4943\n",
            "Epoch 13/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4849 - val_accuracy: 0.8824 - val_loss: 0.5236\n",
            "Epoch 14/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4835 - val_accuracy: 0.8824 - val_loss: 0.5058\n",
            "Epoch 15/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4843 - val_accuracy: 0.8824 - val_loss: 0.5184\n",
            "Epoch 16/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.4927\n",
            "Epoch 17/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5105\n",
            "Epoch 18/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.5329\n",
            "Epoch 19/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4874 - val_accuracy: 0.8824 - val_loss: 0.5370\n",
            "Epoch 20/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7902 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.4851\n",
            "Epoch 21/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7672 - loss: 0.4855 - val_accuracy: 0.8824 - val_loss: 0.4929\n",
            "Epoch 22/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7738 - loss: 0.4835 - val_accuracy: 0.8824 - val_loss: 0.5140\n",
            "Epoch 23/2000\n",
            "61/61 - 9s - 150ms/step - accuracy: 0.7803 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5100\n",
            "Epoch 24/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5042\n",
            "Epoch 25/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5069\n",
            "Epoch 26/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4851 - val_accuracy: 0.8824 - val_loss: 0.5278\n",
            "Epoch 27/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.4923\n",
            "Epoch 28/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4843 - val_accuracy: 0.8824 - val_loss: 0.5067\n",
            "Epoch 29/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5218\n",
            "Epoch 30/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4841 - val_accuracy: 0.8824 - val_loss: 0.5166\n",
            "Epoch 31/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.5058\n",
            "Epoch 32/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5049\n",
            "Epoch 33/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5160\n",
            "Epoch 34/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4842 - val_accuracy: 0.8824 - val_loss: 0.5059\n",
            "Epoch 35/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4836 - val_accuracy: 0.8824 - val_loss: 0.5158\n",
            "Epoch 36/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4849 - val_accuracy: 0.8824 - val_loss: 0.5166\n",
            "Epoch 37/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4851 - val_accuracy: 0.8824 - val_loss: 0.5176\n",
            "Epoch 38/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4842 - val_accuracy: 0.8824 - val_loss: 0.4958\n",
            "Epoch 39/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.5202\n",
            "Epoch 40/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4848 - val_accuracy: 0.8824 - val_loss: 0.5157\n",
            "Epoch 41/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.4988\n",
            "Epoch 42/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7639 - loss: 0.4878 - val_accuracy: 0.8824 - val_loss: 0.4838\n",
            "Epoch 43/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4842 - val_accuracy: 0.8824 - val_loss: 0.4944\n",
            "Epoch 44/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7869 - loss: 0.4844 - val_accuracy: 0.8824 - val_loss: 0.5091\n",
            "Epoch 45/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7803 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5160\n",
            "Epoch 46/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5045\n",
            "Epoch 47/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4846 - val_accuracy: 0.8824 - val_loss: 0.5257\n",
            "Epoch 48/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4836 - val_accuracy: 0.8824 - val_loss: 0.5145\n",
            "Epoch 49/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7639 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.4998\n",
            "Epoch 50/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7836 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5187\n",
            "Epoch 51/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4860 - val_accuracy: 0.8824 - val_loss: 0.5040\n",
            "Epoch 52/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.4938\n",
            "Epoch 53/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4852 - val_accuracy: 0.8824 - val_loss: 0.5192\n",
            "Epoch 54/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.4998\n",
            "Epoch 55/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5279\n",
            "Epoch 56/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4842 - val_accuracy: 0.8824 - val_loss: 0.5098\n",
            "Epoch 57/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5069\n",
            "Epoch 58/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7836 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.4954\n",
            "Epoch 59/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4851 - val_accuracy: 0.8824 - val_loss: 0.4857\n",
            "Epoch 60/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4845 - val_accuracy: 0.8824 - val_loss: 0.5027\n",
            "Epoch 61/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4840 - val_accuracy: 0.8824 - val_loss: 0.5130\n",
            "Epoch 62/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.4963\n",
            "Epoch 63/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7803 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.4980\n",
            "Epoch 64/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5154\n",
            "Epoch 65/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7705 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5092\n",
            "Epoch 66/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4853 - val_accuracy: 0.8824 - val_loss: 0.5352\n",
            "Epoch 67/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4868 - val_accuracy: 0.8824 - val_loss: 0.5007\n",
            "Epoch 68/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.4915\n",
            "Epoch 69/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4841 - val_accuracy: 0.8824 - val_loss: 0.4949\n",
            "Epoch 70/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7770 - loss: 0.4846 - val_accuracy: 0.8824 - val_loss: 0.4910\n",
            "Epoch 71/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5349\n",
            "Epoch 72/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4849 - val_accuracy: 0.8824 - val_loss: 0.5037\n",
            "Epoch 73/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.4935\n",
            "Epoch 74/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4852 - val_accuracy: 0.8824 - val_loss: 0.5301\n",
            "Epoch 75/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4848 - val_accuracy: 0.8824 - val_loss: 0.5107\n",
            "Epoch 76/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5139\n",
            "Epoch 77/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5083\n",
            "Epoch 78/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.4981\n",
            "Epoch 79/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4846 - val_accuracy: 0.8824 - val_loss: 0.4968\n",
            "Epoch 80/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4856 - val_accuracy: 0.8824 - val_loss: 0.4943\n",
            "Epoch 81/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4837 - val_accuracy: 0.8824 - val_loss: 0.5110\n",
            "Epoch 82/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5161\n",
            "Epoch 83/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7836 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.4938\n",
            "Epoch 84/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4849 - val_accuracy: 0.8824 - val_loss: 0.4934\n",
            "Epoch 85/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.4973\n",
            "Epoch 86/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5033\n",
            "Epoch 87/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5161\n",
            "Epoch 88/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5196\n",
            "Epoch 89/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5348\n",
            "Epoch 90/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5121\n",
            "Epoch 91/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4852 - val_accuracy: 0.8824 - val_loss: 0.5205\n",
            "Epoch 92/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5120\n",
            "Epoch 93/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5115\n",
            "Epoch 94/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4845 - val_accuracy: 0.8824 - val_loss: 0.5156\n",
            "Epoch 95/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7738 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5095\n",
            "Epoch 96/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4862 - val_accuracy: 0.8824 - val_loss: 0.4970\n",
            "Epoch 97/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4837 - val_accuracy: 0.8824 - val_loss: 0.5086\n",
            "Epoch 98/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4851 - val_accuracy: 0.8824 - val_loss: 0.4983\n",
            "Epoch 99/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4845 - val_accuracy: 0.8824 - val_loss: 0.4966\n",
            "Epoch 100/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.4869\n",
            "Epoch 101/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5244\n",
            "Epoch 102/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4852 - val_accuracy: 0.8824 - val_loss: 0.5177\n",
            "Epoch 103/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5048\n",
            "Epoch 104/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5120\n",
            "Epoch 105/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7639 - loss: 0.4848 - val_accuracy: 0.8824 - val_loss: 0.4881\n",
            "Epoch 106/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4861 - val_accuracy: 0.8824 - val_loss: 0.4901\n",
            "Epoch 107/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5234\n",
            "Epoch 108/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7836 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.4955\n",
            "Epoch 109/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7639 - loss: 0.4837 - val_accuracy: 0.8824 - val_loss: 0.4973\n",
            "Epoch 110/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4854 - val_accuracy: 0.8824 - val_loss: 0.4952\n",
            "Epoch 111/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5081\n",
            "Epoch 112/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7770 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.4999\n",
            "Epoch 113/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4836 - val_accuracy: 0.8824 - val_loss: 0.4986\n",
            "Epoch 114/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4844 - val_accuracy: 0.8824 - val_loss: 0.5109\n",
            "Epoch 115/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7738 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5125\n",
            "Epoch 116/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4888 - val_accuracy: 0.8824 - val_loss: 0.5184\n",
            "Epoch 117/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5061\n",
            "Epoch 118/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5054\n",
            "Epoch 119/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4835 - val_accuracy: 0.8824 - val_loss: 0.5106\n",
            "Epoch 120/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4837 - val_accuracy: 0.8824 - val_loss: 0.5112\n",
            "Epoch 121/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4860 - val_accuracy: 0.8824 - val_loss: 0.5015\n",
            "Epoch 122/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5149\n",
            "Epoch 123/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5028\n",
            "Epoch 124/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7705 - loss: 0.4864 - val_accuracy: 0.8824 - val_loss: 0.4835\n",
            "Epoch 125/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4835 - val_accuracy: 0.8824 - val_loss: 0.5086\n",
            "Epoch 126/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7836 - loss: 0.4848 - val_accuracy: 0.8824 - val_loss: 0.5163\n",
            "Epoch 127/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.5021\n",
            "Epoch 128/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4843 - val_accuracy: 0.8824 - val_loss: 0.5075\n",
            "Epoch 129/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7869 - loss: 0.4877 - val_accuracy: 0.5294 - val_loss: 0.5559\n",
            "Epoch 130/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4860 - val_accuracy: 0.8824 - val_loss: 0.5121\n",
            "Epoch 131/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.4861\n",
            "Epoch 132/2000\n",
            "61/61 - 9s - 150ms/step - accuracy: 0.7803 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5091\n",
            "Epoch 133/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7672 - loss: 0.4864 - val_accuracy: 0.8824 - val_loss: 0.4940\n",
            "Epoch 134/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7705 - loss: 0.4850 - val_accuracy: 0.8824 - val_loss: 0.5249\n",
            "Epoch 135/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.4932\n",
            "Epoch 136/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7836 - loss: 0.4866 - val_accuracy: 0.8824 - val_loss: 0.4997\n",
            "Epoch 137/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4837 - val_accuracy: 0.8824 - val_loss: 0.5160\n",
            "Epoch 138/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.4987\n",
            "Epoch 139/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4841 - val_accuracy: 0.8824 - val_loss: 0.5044\n",
            "Epoch 140/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5147\n",
            "Epoch 141/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4842 - val_accuracy: 0.8824 - val_loss: 0.5062\n",
            "Epoch 142/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.5173\n",
            "Epoch 143/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7672 - loss: 0.4835 - val_accuracy: 0.8824 - val_loss: 0.5205\n",
            "Epoch 144/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5005\n",
            "Epoch 145/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4865 - val_accuracy: 0.8824 - val_loss: 0.4931\n",
            "Epoch 146/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5363\n",
            "Epoch 147/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4862 - val_accuracy: 0.8824 - val_loss: 0.4784\n",
            "Epoch 148/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4863 - val_accuracy: 0.8824 - val_loss: 0.4897\n",
            "Epoch 149/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4836 - val_accuracy: 0.8824 - val_loss: 0.4953\n",
            "Epoch 150/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5137\n",
            "Epoch 151/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7836 - loss: 0.4836 - val_accuracy: 0.8824 - val_loss: 0.5129\n",
            "Epoch 152/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.4961\n",
            "Epoch 153/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5038\n",
            "Epoch 154/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7672 - loss: 0.4865 - val_accuracy: 0.8824 - val_loss: 0.5205\n",
            "Epoch 155/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4844 - val_accuracy: 0.8824 - val_loss: 0.5017\n",
            "Epoch 156/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7770 - loss: 0.4836 - val_accuracy: 0.8824 - val_loss: 0.5154\n",
            "Epoch 157/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4837 - val_accuracy: 0.8824 - val_loss: 0.4967\n",
            "Epoch 158/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7836 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5147\n",
            "Epoch 159/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7738 - loss: 0.4840 - val_accuracy: 0.8824 - val_loss: 0.5209\n",
            "Epoch 160/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4844 - val_accuracy: 0.8824 - val_loss: 0.5222\n",
            "Epoch 161/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.5273\n",
            "Epoch 162/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4851 - val_accuracy: 0.8824 - val_loss: 0.5143\n",
            "Epoch 163/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4840 - val_accuracy: 0.8824 - val_loss: 0.5261\n",
            "Epoch 164/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4846 - val_accuracy: 0.8824 - val_loss: 0.4992\n",
            "Epoch 165/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4852 - val_accuracy: 0.8824 - val_loss: 0.5052\n",
            "Epoch 166/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4841 - val_accuracy: 0.8824 - val_loss: 0.5154\n",
            "Epoch 167/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4853 - val_accuracy: 0.8824 - val_loss: 0.5371\n",
            "Epoch 168/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4848 - val_accuracy: 0.8824 - val_loss: 0.5186\n",
            "Epoch 169/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5004\n",
            "Epoch 170/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5050\n",
            "Epoch 171/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7770 - loss: 0.4850 - val_accuracy: 0.8824 - val_loss: 0.5321\n",
            "Epoch 172/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.4937\n",
            "Epoch 173/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4844 - val_accuracy: 0.8824 - val_loss: 0.5136\n",
            "Epoch 174/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5143\n",
            "Epoch 175/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.5351\n",
            "Epoch 176/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4849 - val_accuracy: 0.8824 - val_loss: 0.5134\n",
            "Epoch 177/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4847 - val_accuracy: 0.8824 - val_loss: 0.4859\n",
            "Epoch 178/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7672 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5247\n",
            "Epoch 179/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4844 - val_accuracy: 0.8824 - val_loss: 0.5148\n",
            "Epoch 180/2000\n",
            "61/61 - 9s - 150ms/step - accuracy: 0.7770 - loss: 0.4836 - val_accuracy: 0.8824 - val_loss: 0.5087\n",
            "Epoch 181/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4845 - val_accuracy: 0.8824 - val_loss: 0.5007\n",
            "Epoch 182/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4840 - val_accuracy: 0.8824 - val_loss: 0.5201\n",
            "Epoch 183/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.4951\n",
            "Epoch 184/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7705 - loss: 0.4845 - val_accuracy: 0.8824 - val_loss: 0.4936\n",
            "Epoch 185/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.4983\n",
            "Epoch 186/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5005\n",
            "Epoch 187/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4848 - val_accuracy: 0.8824 - val_loss: 0.4895\n",
            "Epoch 188/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4843 - val_accuracy: 0.8824 - val_loss: 0.5130\n",
            "Epoch 189/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4861 - val_accuracy: 0.8824 - val_loss: 0.5328\n",
            "Epoch 190/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4845 - val_accuracy: 0.8824 - val_loss: 0.5055\n",
            "Epoch 191/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7672 - loss: 0.4845 - val_accuracy: 0.8824 - val_loss: 0.4935\n",
            "Epoch 192/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4837 - val_accuracy: 0.8824 - val_loss: 0.5158\n",
            "Epoch 193/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4850 - val_accuracy: 0.8824 - val_loss: 0.5029\n",
            "Epoch 194/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4836 - val_accuracy: 0.8824 - val_loss: 0.5084\n",
            "Epoch 195/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.5244\n",
            "Epoch 196/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4840 - val_accuracy: 0.8824 - val_loss: 0.5068\n",
            "Epoch 197/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4851 - val_accuracy: 0.8824 - val_loss: 0.5039\n",
            "Epoch 198/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7869 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.5102\n",
            "Epoch 199/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.5134\n",
            "Epoch 200/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5026\n",
            "Epoch 201/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.5152\n",
            "Epoch 202/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5198\n",
            "Epoch 203/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4835 - val_accuracy: 0.8824 - val_loss: 0.5091\n",
            "Epoch 204/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4852 - val_accuracy: 0.8824 - val_loss: 0.5358\n",
            "Epoch 205/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4849 - val_accuracy: 0.8824 - val_loss: 0.5099\n",
            "Epoch 206/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4844 - val_accuracy: 0.8824 - val_loss: 0.5075\n",
            "Epoch 207/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5079\n",
            "Epoch 208/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5111\n",
            "Epoch 209/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7803 - loss: 0.4843 - val_accuracy: 0.8824 - val_loss: 0.5073\n",
            "Epoch 210/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7738 - loss: 0.4862 - val_accuracy: 0.8824 - val_loss: 0.4900\n",
            "Epoch 211/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5152\n",
            "Epoch 212/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4840 - val_accuracy: 0.8824 - val_loss: 0.5147\n",
            "Epoch 213/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4840 - val_accuracy: 0.8824 - val_loss: 0.4924\n",
            "Epoch 214/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5180\n",
            "Epoch 215/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4848 - val_accuracy: 0.8824 - val_loss: 0.5067\n",
            "Epoch 216/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5067\n",
            "Epoch 217/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4870 - val_accuracy: 0.8824 - val_loss: 0.5021\n",
            "Epoch 218/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4847 - val_accuracy: 0.8824 - val_loss: 0.5120\n",
            "Epoch 219/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5057\n",
            "Epoch 220/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4850 - val_accuracy: 0.8824 - val_loss: 0.5011\n",
            "Epoch 221/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7836 - loss: 0.4841 - val_accuracy: 0.8824 - val_loss: 0.5152\n",
            "Epoch 222/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.5268\n",
            "Epoch 223/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7672 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.4886\n",
            "Epoch 224/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4835 - val_accuracy: 0.8824 - val_loss: 0.5201\n",
            "Epoch 225/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.5159\n",
            "Epoch 226/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.5150\n",
            "Epoch 227/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4850 - val_accuracy: 0.8824 - val_loss: 0.4946\n",
            "Epoch 228/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4840 - val_accuracy: 0.8824 - val_loss: 0.5148\n",
            "Epoch 229/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.5054\n",
            "Epoch 230/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4846 - val_accuracy: 0.8824 - val_loss: 0.5074\n",
            "Epoch 231/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5232\n",
            "Epoch 232/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.4998\n",
            "Epoch 233/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4854 - val_accuracy: 0.8824 - val_loss: 0.4934\n",
            "Epoch 234/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5431\n",
            "Epoch 235/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4856 - val_accuracy: 0.8824 - val_loss: 0.5151\n",
            "Epoch 236/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7705 - loss: 0.4837 - val_accuracy: 0.8824 - val_loss: 0.4898\n",
            "Epoch 237/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7836 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5190\n",
            "Epoch 238/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7738 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5042\n",
            "Epoch 239/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4848 - val_accuracy: 0.8824 - val_loss: 0.5051\n",
            "Epoch 240/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4853 - val_accuracy: 0.8824 - val_loss: 0.5075\n",
            "Epoch 241/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5165\n",
            "Epoch 242/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5034\n",
            "Epoch 243/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4856 - val_accuracy: 0.8824 - val_loss: 0.5379\n",
            "Epoch 244/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4837 - val_accuracy: 0.8824 - val_loss: 0.5071\n",
            "Epoch 245/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4850 - val_accuracy: 0.8824 - val_loss: 0.5099\n",
            "Epoch 246/2000\n",
            "61/61 - 564s - 9s/step - accuracy: 0.7738 - loss: 0.4843 - val_accuracy: 0.8824 - val_loss: 0.5123\n",
            "Epoch 247/2000\n",
            "61/61 - 383s - 6s/step - accuracy: 0.7803 - loss: 0.4851 - val_accuracy: 0.8824 - val_loss: 0.5128\n",
            "Epoch 248/2000\n",
            "61/61 - 123s - 2s/step - accuracy: 0.7803 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5097\n",
            "Epoch 249/2000\n",
            "61/61 - 934s - 15s/step - accuracy: 0.7639 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.4994\n",
            "Epoch 250/2000\n",
            "61/61 - 9s - 142ms/step - accuracy: 0.7803 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5107\n",
            "Epoch 251/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4837 - val_accuracy: 0.8824 - val_loss: 0.4912\n",
            "Epoch 252/2000\n",
            "61/61 - 344s - 6s/step - accuracy: 0.7770 - loss: 0.4855 - val_accuracy: 0.8824 - val_loss: 0.5216\n",
            "Epoch 253/2000\n",
            "61/61 - 903s - 15s/step - accuracy: 0.7803 - loss: 0.4854 - val_accuracy: 0.8824 - val_loss: 0.5299\n",
            "Epoch 254/2000\n",
            "61/61 - 724s - 12s/step - accuracy: 0.7738 - loss: 0.4843 - val_accuracy: 0.8824 - val_loss: 0.5070\n",
            "Epoch 255/2000\n",
            "61/61 - 10s - 163ms/step - accuracy: 0.7803 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5140\n",
            "Epoch 256/2000\n",
            "61/61 - 9s - 154ms/step - accuracy: 0.7738 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.5164\n",
            "Epoch 257/2000\n",
            "61/61 - 9s - 152ms/step - accuracy: 0.7705 - loss: 0.4859 - val_accuracy: 0.8824 - val_loss: 0.5174\n",
            "Epoch 258/2000\n",
            "61/61 - 16s - 256ms/step - accuracy: 0.7803 - loss: 0.4901 - val_accuracy: 0.5294 - val_loss: 0.5700\n",
            "Epoch 259/2000\n",
            "61/61 - 21s - 337ms/step - accuracy: 0.7705 - loss: 0.4861 - val_accuracy: 0.8824 - val_loss: 0.4975\n",
            "Epoch 260/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7738 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5058\n",
            "Epoch 261/2000\n",
            "61/61 - 9s - 153ms/step - accuracy: 0.7803 - loss: 0.4860 - val_accuracy: 0.8824 - val_loss: 0.5013\n",
            "Epoch 262/2000\n",
            "61/61 - 9s - 150ms/step - accuracy: 0.7836 - loss: 0.4850 - val_accuracy: 0.8824 - val_loss: 0.5007\n",
            "Epoch 263/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7672 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5049\n",
            "Epoch 264/2000\n",
            "61/61 - 9s - 154ms/step - accuracy: 0.7738 - loss: 0.4869 - val_accuracy: 0.8824 - val_loss: 0.5175\n",
            "Epoch 265/2000\n",
            "61/61 - 9s - 153ms/step - accuracy: 0.7770 - loss: 0.4852 - val_accuracy: 0.8824 - val_loss: 0.5199\n",
            "Epoch 266/2000\n",
            "61/61 - 131s - 2s/step - accuracy: 0.7803 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5099\n",
            "Epoch 267/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7705 - loss: 0.4840 - val_accuracy: 0.8824 - val_loss: 0.5009\n",
            "Epoch 268/2000\n",
            "61/61 - 35s - 580ms/step - accuracy: 0.7770 - loss: 0.4844 - val_accuracy: 0.8824 - val_loss: 0.5004\n",
            "Epoch 269/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4837 - val_accuracy: 0.8824 - val_loss: 0.5057\n",
            "Epoch 270/2000\n",
            "61/61 - 9s - 150ms/step - accuracy: 0.7770 - loss: 0.4843 - val_accuracy: 0.8824 - val_loss: 0.5070\n",
            "Epoch 271/2000\n",
            "61/61 - 9s - 152ms/step - accuracy: 0.7803 - loss: 0.4854 - val_accuracy: 0.8824 - val_loss: 0.5014\n",
            "Epoch 272/2000\n",
            "61/61 - 10s - 158ms/step - accuracy: 0.7803 - loss: 0.4835 - val_accuracy: 0.8824 - val_loss: 0.4993\n",
            "Epoch 273/2000\n",
            "61/61 - 33s - 540ms/step - accuracy: 0.7770 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.5155\n",
            "Epoch 274/2000\n",
            "61/61 - 9s - 155ms/step - accuracy: 0.7770 - loss: 0.4856 - val_accuracy: 0.8824 - val_loss: 0.5057\n",
            "Epoch 275/2000\n",
            "61/61 - 54s - 889ms/step - accuracy: 0.7770 - loss: 0.4850 - val_accuracy: 0.8824 - val_loss: 0.5042\n",
            "Epoch 276/2000\n",
            "61/61 - 9s - 150ms/step - accuracy: 0.7738 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5074\n",
            "Epoch 277/2000\n",
            "61/61 - 120s - 2s/step - accuracy: 0.7672 - loss: 0.4836 - val_accuracy: 0.8824 - val_loss: 0.5113\n",
            "Epoch 278/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7705 - loss: 0.4842 - val_accuracy: 0.8824 - val_loss: 0.5054\n",
            "Epoch 279/2000\n",
            "61/61 - 9s - 150ms/step - accuracy: 0.7738 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.4956\n",
            "Epoch 280/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7803 - loss: 0.4873 - val_accuracy: 0.8824 - val_loss: 0.4986\n",
            "Epoch 281/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7738 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.5068\n",
            "Epoch 282/2000\n",
            "61/61 - 32s - 519ms/step - accuracy: 0.7803 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.4997\n",
            "Epoch 283/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7770 - loss: 0.4843 - val_accuracy: 0.8824 - val_loss: 0.5011\n",
            "Epoch 284/2000\n",
            "61/61 - 38s - 628ms/step - accuracy: 0.7803 - loss: 0.4853 - val_accuracy: 0.8824 - val_loss: 0.5283\n",
            "Epoch 285/2000\n",
            "61/61 - 9s - 152ms/step - accuracy: 0.7705 - loss: 0.4846 - val_accuracy: 0.8824 - val_loss: 0.4891\n",
            "Epoch 286/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7770 - loss: 0.4854 - val_accuracy: 0.8824 - val_loss: 0.4873\n",
            "Epoch 287/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7770 - loss: 0.4844 - val_accuracy: 0.8824 - val_loss: 0.5102\n",
            "Epoch 288/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7803 - loss: 0.4837 - val_accuracy: 0.8824 - val_loss: 0.5079\n",
            "Epoch 289/2000\n",
            "61/61 - 1031s - 17s/step - accuracy: 0.7770 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5089\n",
            "Epoch 290/2000\n",
            "61/61 - 1132s - 19s/step - accuracy: 0.7738 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.4992\n",
            "Epoch 291/2000\n",
            "61/61 - 399s - 7s/step - accuracy: 0.7705 - loss: 0.4853 - val_accuracy: 0.8824 - val_loss: 0.4902\n",
            "Epoch 292/2000\n",
            "61/61 - 1247s - 20s/step - accuracy: 0.7836 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.4991\n",
            "Epoch 293/2000\n",
            "61/61 - 9s - 143ms/step - accuracy: 0.7803 - loss: 0.4859 - val_accuracy: 0.8824 - val_loss: 0.4949\n",
            "Epoch 294/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.5056\n",
            "Epoch 295/2000\n",
            "61/61 - 9s - 143ms/step - accuracy: 0.7738 - loss: 0.4847 - val_accuracy: 0.8824 - val_loss: 0.5037\n",
            "Epoch 296/2000\n",
            "61/61 - 10s - 158ms/step - accuracy: 0.7803 - loss: 0.4861 - val_accuracy: 0.8824 - val_loss: 0.5023\n",
            "Epoch 297/2000\n",
            "61/61 - 288s - 5s/step - accuracy: 0.7770 - loss: 0.4859 - val_accuracy: 0.8824 - val_loss: 0.5443\n",
            "Epoch 298/2000\n",
            "61/61 - 9s - 150ms/step - accuracy: 0.7803 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5018\n",
            "Epoch 299/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7836 - loss: 0.4874 - val_accuracy: 0.8824 - val_loss: 0.5051\n",
            "Epoch 300/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7803 - loss: 0.4857 - val_accuracy: 0.8824 - val_loss: 0.5019\n",
            "Epoch 301/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7705 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5151\n",
            "Epoch 302/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4892 - val_accuracy: 0.8824 - val_loss: 0.5215\n",
            "Epoch 303/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.4975\n",
            "Epoch 304/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.4953\n",
            "Epoch 305/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4853 - val_accuracy: 0.8824 - val_loss: 0.5015\n",
            "Epoch 306/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4857 - val_accuracy: 0.8824 - val_loss: 0.4923\n",
            "Epoch 307/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4840 - val_accuracy: 0.8824 - val_loss: 0.5029\n",
            "Epoch 308/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4852 - val_accuracy: 0.8824 - val_loss: 0.5116\n",
            "Epoch 309/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4866 - val_accuracy: 0.8824 - val_loss: 0.5220\n",
            "Epoch 310/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7770 - loss: 0.4845 - val_accuracy: 0.8824 - val_loss: 0.5171\n",
            "Epoch 311/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7770 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5012\n",
            "Epoch 312/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7803 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5083\n",
            "Epoch 313/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7738 - loss: 0.4856 - val_accuracy: 0.8824 - val_loss: 0.5035\n",
            "Epoch 314/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.5059\n",
            "Epoch 315/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4851 - val_accuracy: 0.8824 - val_loss: 0.5366\n",
            "Epoch 316/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.5122\n",
            "Epoch 317/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4835 - val_accuracy: 0.8824 - val_loss: 0.5045\n",
            "Epoch 318/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4835 - val_accuracy: 0.8824 - val_loss: 0.5150\n",
            "Epoch 319/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5164\n",
            "Epoch 320/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4844 - val_accuracy: 0.8824 - val_loss: 0.5024\n",
            "Epoch 321/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4869 - val_accuracy: 0.8824 - val_loss: 0.5035\n",
            "Epoch 322/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4858 - val_accuracy: 0.8824 - val_loss: 0.5140\n",
            "Epoch 323/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.4992\n",
            "Epoch 324/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5015\n",
            "Epoch 325/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4864 - val_accuracy: 0.8824 - val_loss: 0.5014\n",
            "Epoch 326/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4843 - val_accuracy: 0.8824 - val_loss: 0.4988\n",
            "Epoch 327/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5021\n",
            "Epoch 328/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4848 - val_accuracy: 0.8824 - val_loss: 0.4966\n",
            "Epoch 329/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4837 - val_accuracy: 0.8824 - val_loss: 0.5186\n",
            "Epoch 330/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4855 - val_accuracy: 0.8824 - val_loss: 0.4961\n",
            "Epoch 331/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4860 - val_accuracy: 0.8824 - val_loss: 0.4890\n",
            "Epoch 332/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4859 - val_accuracy: 0.8824 - val_loss: 0.4994\n",
            "Epoch 333/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.4978\n",
            "Epoch 334/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5214\n",
            "Epoch 335/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4862 - val_accuracy: 0.8824 - val_loss: 0.5104\n",
            "Epoch 336/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7672 - loss: 0.4844 - val_accuracy: 0.8824 - val_loss: 0.5038\n",
            "Epoch 337/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4855 - val_accuracy: 0.8824 - val_loss: 0.5140\n",
            "Epoch 338/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4847 - val_accuracy: 0.8824 - val_loss: 0.5220\n",
            "Epoch 339/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5025\n",
            "Epoch 340/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5026\n",
            "Epoch 341/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5046\n",
            "Epoch 342/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4842 - val_accuracy: 0.8824 - val_loss: 0.5084\n",
            "Epoch 343/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.4951\n",
            "Epoch 344/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5110\n",
            "Epoch 345/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7639 - loss: 0.4851 - val_accuracy: 0.8824 - val_loss: 0.5020\n",
            "Epoch 346/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4837 - val_accuracy: 0.8824 - val_loss: 0.4991\n",
            "Epoch 347/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7836 - loss: 0.4841 - val_accuracy: 0.8824 - val_loss: 0.4850\n",
            "Epoch 348/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4843 - val_accuracy: 0.8824 - val_loss: 0.5072\n",
            "Epoch 349/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5115\n",
            "Epoch 350/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7770 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.5157\n",
            "Epoch 351/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4840 - val_accuracy: 0.8824 - val_loss: 0.5211\n",
            "Epoch 352/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4862 - val_accuracy: 0.8824 - val_loss: 0.5198\n",
            "Epoch 353/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4836 - val_accuracy: 0.8824 - val_loss: 0.5063\n",
            "Epoch 354/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.4997\n",
            "Epoch 355/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.4886\n",
            "Epoch 356/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.4953\n",
            "Epoch 357/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7770 - loss: 0.4847 - val_accuracy: 0.8824 - val_loss: 0.5223\n",
            "Epoch 358/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7836 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.4914\n",
            "Epoch 359/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7705 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5161\n",
            "Epoch 360/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7770 - loss: 0.4853 - val_accuracy: 0.8824 - val_loss: 0.5063\n",
            "Epoch 361/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.4934\n",
            "Epoch 362/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7770 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5045\n",
            "Epoch 363/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7738 - loss: 0.4858 - val_accuracy: 0.8824 - val_loss: 0.4919\n",
            "Epoch 364/2000\n",
            "61/61 - 9s - 143ms/step - accuracy: 0.7738 - loss: 0.4856 - val_accuracy: 0.8824 - val_loss: 0.5281\n",
            "Epoch 365/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4841 - val_accuracy: 0.8824 - val_loss: 0.5067\n",
            "Epoch 366/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4840 - val_accuracy: 0.8824 - val_loss: 0.5249\n",
            "Epoch 367/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.4926\n",
            "Epoch 368/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4845 - val_accuracy: 0.8824 - val_loss: 0.4968\n",
            "Epoch 369/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4835 - val_accuracy: 0.8824 - val_loss: 0.5270\n",
            "Epoch 370/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4841 - val_accuracy: 0.8824 - val_loss: 0.5150\n",
            "Epoch 371/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4843 - val_accuracy: 0.8824 - val_loss: 0.4937\n",
            "Epoch 372/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4854 - val_accuracy: 0.8824 - val_loss: 0.5146\n",
            "Epoch 373/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4836 - val_accuracy: 0.8824 - val_loss: 0.5206\n",
            "Epoch 374/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5030\n",
            "Epoch 375/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7672 - loss: 0.4852 - val_accuracy: 0.8824 - val_loss: 0.5152\n",
            "Epoch 376/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4849 - val_accuracy: 0.8824 - val_loss: 0.5170\n",
            "Epoch 377/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.5098\n",
            "Epoch 378/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4848 - val_accuracy: 0.8824 - val_loss: 0.5147\n",
            "Epoch 379/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5033\n",
            "Epoch 380/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4848 - val_accuracy: 0.8824 - val_loss: 0.5062\n",
            "Epoch 381/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4837 - val_accuracy: 0.8824 - val_loss: 0.5164\n",
            "Epoch 382/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4849 - val_accuracy: 0.8824 - val_loss: 0.4945\n",
            "Epoch 383/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4847 - val_accuracy: 0.8824 - val_loss: 0.4995\n",
            "Epoch 384/2000\n",
            "61/61 - 38s - 615ms/step - accuracy: 0.7738 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5140\n",
            "Epoch 385/2000\n",
            "61/61 - 10s - 157ms/step - accuracy: 0.7803 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.5181\n",
            "Epoch 386/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7770 - loss: 0.4845 - val_accuracy: 0.8824 - val_loss: 0.5294\n",
            "Epoch 387/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7705 - loss: 0.4849 - val_accuracy: 0.8824 - val_loss: 0.5072\n",
            "Epoch 388/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7738 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.5150\n",
            "Epoch 389/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5035\n",
            "Epoch 390/2000\n",
            "61/61 - 906s - 15s/step - accuracy: 0.7770 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5007\n",
            "Epoch 391/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7770 - loss: 0.4845 - val_accuracy: 0.8824 - val_loss: 0.5192\n",
            "Epoch 392/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5066\n",
            "Epoch 393/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7705 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5066\n",
            "Epoch 394/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4841 - val_accuracy: 0.8824 - val_loss: 0.5202\n",
            "Epoch 395/2000\n",
            "61/61 - 110s - 2s/step - accuracy: 0.7803 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5030\n",
            "Epoch 396/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7836 - loss: 0.4855 - val_accuracy: 0.8824 - val_loss: 0.5143\n",
            "Epoch 397/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7738 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5035\n",
            "Epoch 398/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5106\n",
            "Epoch 399/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4846 - val_accuracy: 0.8824 - val_loss: 0.4909\n",
            "Epoch 400/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5157\n",
            "Epoch 401/2000\n",
            "61/61 - 587s - 10s/step - accuracy: 0.7738 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.5109\n",
            "Epoch 402/2000\n",
            "61/61 - 9s - 143ms/step - accuracy: 0.7803 - loss: 0.4852 - val_accuracy: 0.8824 - val_loss: 0.5163\n",
            "Epoch 403/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7672 - loss: 0.4846 - val_accuracy: 0.8824 - val_loss: 0.4884\n",
            "Epoch 404/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7705 - loss: 0.4870 - val_accuracy: 0.8824 - val_loss: 0.5048\n",
            "Epoch 405/2000\n",
            "61/61 - 9s - 143ms/step - accuracy: 0.7770 - loss: 0.4859 - val_accuracy: 0.8824 - val_loss: 0.5103\n",
            "Epoch 406/2000\n",
            "61/61 - 423s - 7s/step - accuracy: 0.7770 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5096\n",
            "Epoch 407/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4858 - val_accuracy: 0.8824 - val_loss: 0.5077\n",
            "Epoch 408/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5067\n",
            "Epoch 409/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7836 - loss: 0.4859 - val_accuracy: 0.8824 - val_loss: 0.4901\n",
            "Epoch 410/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7836 - loss: 0.4854 - val_accuracy: 0.8824 - val_loss: 0.5011\n",
            "Epoch 411/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.4950\n",
            "Epoch 412/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.4959\n",
            "Epoch 413/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7770 - loss: 0.4835 - val_accuracy: 0.8824 - val_loss: 0.5122\n",
            "Epoch 414/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.4968\n",
            "Epoch 415/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4837 - val_accuracy: 0.8824 - val_loss: 0.5050\n",
            "Epoch 416/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4859 - val_accuracy: 0.8824 - val_loss: 0.4964\n",
            "Epoch 417/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4856 - val_accuracy: 0.8824 - val_loss: 0.5160\n",
            "Epoch 418/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7770 - loss: 0.4894 - val_accuracy: 0.8824 - val_loss: 0.4895\n",
            "Epoch 419/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4840 - val_accuracy: 0.8824 - val_loss: 0.5018\n",
            "Epoch 420/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4852 - val_accuracy: 0.8824 - val_loss: 0.4941\n",
            "Epoch 421/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4847 - val_accuracy: 0.8824 - val_loss: 0.5051\n",
            "Epoch 422/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7738 - loss: 0.4854 - val_accuracy: 0.8824 - val_loss: 0.5070\n",
            "Epoch 423/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.4880\n",
            "Epoch 424/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4859 - val_accuracy: 0.8824 - val_loss: 0.5107\n",
            "Epoch 425/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4843 - val_accuracy: 0.8824 - val_loss: 0.5046\n",
            "Epoch 426/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4878 - val_accuracy: 0.8824 - val_loss: 0.5105\n",
            "Epoch 427/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4845 - val_accuracy: 0.8824 - val_loss: 0.4985\n",
            "Epoch 428/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4845 - val_accuracy: 0.8824 - val_loss: 0.5221\n",
            "Epoch 429/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7836 - loss: 0.4845 - val_accuracy: 0.8824 - val_loss: 0.4853\n",
            "Epoch 430/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4849 - val_accuracy: 0.8824 - val_loss: 0.5120\n",
            "Epoch 431/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5140\n",
            "Epoch 432/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.5116\n",
            "Epoch 433/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7836 - loss: 0.4898 - val_accuracy: 0.8824 - val_loss: 0.5251\n",
            "Epoch 434/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5124\n",
            "Epoch 435/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5008\n",
            "Epoch 436/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4854 - val_accuracy: 0.8824 - val_loss: 0.4951\n",
            "Epoch 437/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4845 - val_accuracy: 0.8824 - val_loss: 0.4938\n",
            "Epoch 438/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5269\n",
            "Epoch 439/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4843 - val_accuracy: 0.8824 - val_loss: 0.5304\n",
            "Epoch 440/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5078\n",
            "Epoch 441/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4835 - val_accuracy: 0.8824 - val_loss: 0.4953\n",
            "Epoch 442/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5148\n",
            "Epoch 443/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4854 - val_accuracy: 0.8824 - val_loss: 0.5192\n",
            "Epoch 444/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4842 - val_accuracy: 0.8824 - val_loss: 0.5293\n",
            "Epoch 445/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5000\n",
            "Epoch 446/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5233\n",
            "Epoch 447/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5159\n",
            "Epoch 448/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5120\n",
            "Epoch 449/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4877 - val_accuracy: 0.8824 - val_loss: 0.5048\n",
            "Epoch 450/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5084\n",
            "Epoch 451/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4840 - val_accuracy: 0.8824 - val_loss: 0.5194\n",
            "Epoch 452/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4844 - val_accuracy: 0.8824 - val_loss: 0.5260\n",
            "Epoch 453/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4856 - val_accuracy: 0.8824 - val_loss: 0.4961\n",
            "Epoch 454/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5070\n",
            "Epoch 455/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7902 - loss: 0.4847 - val_accuracy: 0.8824 - val_loss: 0.5320\n",
            "Epoch 456/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4863 - val_accuracy: 0.8824 - val_loss: 0.5180\n",
            "Epoch 457/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5086\n",
            "Epoch 458/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.5111\n",
            "Epoch 459/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4836 - val_accuracy: 0.8824 - val_loss: 0.4984\n",
            "Epoch 460/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4837 - val_accuracy: 0.8824 - val_loss: 0.5186\n",
            "Epoch 461/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5085\n",
            "Epoch 462/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5067\n",
            "Epoch 463/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7672 - loss: 0.4836 - val_accuracy: 0.8824 - val_loss: 0.4997\n",
            "Epoch 464/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7738 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5033\n",
            "Epoch 465/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7770 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.5169\n",
            "Epoch 466/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.5010\n",
            "Epoch 467/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4840 - val_accuracy: 0.8824 - val_loss: 0.5079\n",
            "Epoch 468/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5103\n",
            "Epoch 469/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4849 - val_accuracy: 0.8824 - val_loss: 0.4937\n",
            "Epoch 470/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7738 - loss: 0.4843 - val_accuracy: 0.8824 - val_loss: 0.5217\n",
            "Epoch 471/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.4994\n",
            "Epoch 472/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7705 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5016\n",
            "Epoch 473/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5124\n",
            "Epoch 474/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4852 - val_accuracy: 0.8824 - val_loss: 0.5243\n",
            "Epoch 475/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4836 - val_accuracy: 0.8824 - val_loss: 0.5204\n",
            "Epoch 476/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5166\n",
            "Epoch 477/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4858 - val_accuracy: 0.8824 - val_loss: 0.5304\n",
            "Epoch 478/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5040\n",
            "Epoch 479/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.4987\n",
            "Epoch 480/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4843 - val_accuracy: 0.8824 - val_loss: 0.5279\n",
            "Epoch 481/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5105\n",
            "Epoch 482/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7738 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.4996\n",
            "Epoch 483/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7836 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.5219\n",
            "Epoch 484/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5106\n",
            "Epoch 485/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5142\n",
            "Epoch 486/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4849 - val_accuracy: 0.8824 - val_loss: 0.5347\n",
            "Epoch 487/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4841 - val_accuracy: 0.8824 - val_loss: 0.5076\n",
            "Epoch 488/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7705 - loss: 0.4851 - val_accuracy: 0.8824 - val_loss: 0.5044\n",
            "Epoch 489/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7770 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5154\n",
            "Epoch 490/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7738 - loss: 0.4848 - val_accuracy: 0.8824 - val_loss: 0.5074\n",
            "Epoch 491/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5115\n",
            "Epoch 492/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7836 - loss: 0.4843 - val_accuracy: 0.8824 - val_loss: 0.5263\n",
            "Epoch 493/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7607 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.4976\n",
            "Epoch 494/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7770 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5063\n",
            "Epoch 495/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5140\n",
            "Epoch 496/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4836 - val_accuracy: 0.8824 - val_loss: 0.4975\n",
            "Epoch 497/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7738 - loss: 0.4836 - val_accuracy: 0.8824 - val_loss: 0.5136\n",
            "Epoch 498/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.5093\n",
            "Epoch 499/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7672 - loss: 0.4856 - val_accuracy: 0.8824 - val_loss: 0.4911\n",
            "Epoch 500/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4845 - val_accuracy: 0.8824 - val_loss: 0.5107\n",
            "Epoch 501/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4837 - val_accuracy: 0.8824 - val_loss: 0.5063\n",
            "Epoch 502/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7705 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.4953\n",
            "Epoch 503/2000\n",
            "61/61 - 9s - 143ms/step - accuracy: 0.7738 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5166\n",
            "Epoch 504/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4842 - val_accuracy: 0.8824 - val_loss: 0.5093\n",
            "Epoch 505/2000\n",
            "61/61 - 9s - 143ms/step - accuracy: 0.7770 - loss: 0.4853 - val_accuracy: 0.8824 - val_loss: 0.5419\n",
            "Epoch 506/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7705 - loss: 0.4845 - val_accuracy: 0.8824 - val_loss: 0.5226\n",
            "Epoch 507/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7672 - loss: 0.4854 - val_accuracy: 0.8824 - val_loss: 0.4965\n",
            "Epoch 508/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7836 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5402\n",
            "Epoch 509/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5090\n",
            "Epoch 510/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5089\n",
            "Epoch 511/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5254\n",
            "Epoch 512/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.5137\n",
            "Epoch 513/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.5047\n",
            "Epoch 514/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7672 - loss: 0.4836 - val_accuracy: 0.8824 - val_loss: 0.5041\n",
            "Epoch 515/2000\n",
            "61/61 - 9s - 150ms/step - accuracy: 0.7738 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5093\n",
            "Epoch 516/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5130\n",
            "Epoch 517/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4860 - val_accuracy: 0.8824 - val_loss: 0.5341\n",
            "Epoch 518/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7672 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.5056\n",
            "Epoch 519/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7672 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5158\n",
            "Epoch 520/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5228\n",
            "Epoch 521/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5088\n",
            "Epoch 522/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5014\n",
            "Epoch 523/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4865 - val_accuracy: 0.8824 - val_loss: 0.4973\n",
            "Epoch 524/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4874 - val_accuracy: 0.8824 - val_loss: 0.4982\n",
            "Epoch 525/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4869 - val_accuracy: 0.8824 - val_loss: 0.5130\n",
            "Epoch 526/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5114\n",
            "Epoch 527/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4817 - val_accuracy: 0.8824 - val_loss: 0.5074\n",
            "Epoch 528/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4836 - val_accuracy: 0.8824 - val_loss: 0.5362\n",
            "Epoch 529/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.5073\n",
            "Epoch 530/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.5039\n",
            "Epoch 531/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5265\n",
            "Epoch 532/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4872 - val_accuracy: 0.8824 - val_loss: 0.5269\n",
            "Epoch 533/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5188\n",
            "Epoch 534/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5086\n",
            "Epoch 535/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4842 - val_accuracy: 0.8824 - val_loss: 0.5261\n",
            "Epoch 536/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.5148\n",
            "Epoch 537/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.5136\n",
            "Epoch 538/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5227\n",
            "Epoch 539/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5212\n",
            "Epoch 540/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7672 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5048\n",
            "Epoch 541/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5179\n",
            "Epoch 542/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5094\n",
            "Epoch 543/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7836 - loss: 0.4847 - val_accuracy: 0.8824 - val_loss: 0.5224\n",
            "Epoch 544/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5005\n",
            "Epoch 545/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4853 - val_accuracy: 0.8824 - val_loss: 0.5004\n",
            "Epoch 546/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5101\n",
            "Epoch 547/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4835 - val_accuracy: 0.8824 - val_loss: 0.5344\n",
            "Epoch 548/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4851 - val_accuracy: 0.8824 - val_loss: 0.5230\n",
            "Epoch 549/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7836 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.5191\n",
            "Epoch 550/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5303\n",
            "Epoch 551/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5021\n",
            "Epoch 552/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4848 - val_accuracy: 0.8824 - val_loss: 0.4996\n",
            "Epoch 553/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5211\n",
            "Epoch 554/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.5062\n",
            "Epoch 555/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.4988\n",
            "Epoch 556/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4863 - val_accuracy: 0.8824 - val_loss: 0.5269\n",
            "Epoch 557/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.4997\n",
            "Epoch 558/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5251\n",
            "Epoch 559/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5109\n",
            "Epoch 560/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.5146\n",
            "Epoch 561/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5178\n",
            "Epoch 562/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4840 - val_accuracy: 0.8824 - val_loss: 0.5184\n",
            "Epoch 563/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4846 - val_accuracy: 0.8824 - val_loss: 0.5213\n",
            "Epoch 564/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5075\n",
            "Epoch 565/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4846 - val_accuracy: 0.8824 - val_loss: 0.5147\n",
            "Epoch 566/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5202\n",
            "Epoch 567/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5124\n",
            "Epoch 568/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4850 - val_accuracy: 0.8824 - val_loss: 0.5069\n",
            "Epoch 569/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5161\n",
            "Epoch 570/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5136\n",
            "Epoch 571/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5166\n",
            "Epoch 572/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5256\n",
            "Epoch 573/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4840 - val_accuracy: 0.8824 - val_loss: 0.5185\n",
            "Epoch 574/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7639 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5028\n",
            "Epoch 575/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5049\n",
            "Epoch 576/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5230\n",
            "Epoch 577/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5267\n",
            "Epoch 578/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5091\n",
            "Epoch 579/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4866 - val_accuracy: 0.8824 - val_loss: 0.5264\n",
            "Epoch 580/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.5223\n",
            "Epoch 581/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5154\n",
            "Epoch 582/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5018\n",
            "Epoch 583/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5125\n",
            "Epoch 584/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7803 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5095\n",
            "Epoch 585/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5083\n",
            "Epoch 586/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4817 - val_accuracy: 0.8824 - val_loss: 0.5171\n",
            "Epoch 587/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7672 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5114\n",
            "Epoch 588/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5113\n",
            "Epoch 589/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.4975\n",
            "Epoch 590/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5070\n",
            "Epoch 591/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5024\n",
            "Epoch 592/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5188\n",
            "Epoch 593/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7639 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5125\n",
            "Epoch 594/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5066\n",
            "Epoch 595/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4848 - val_accuracy: 0.8824 - val_loss: 0.5245\n",
            "Epoch 596/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5031\n",
            "Epoch 597/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7836 - loss: 0.4843 - val_accuracy: 0.8824 - val_loss: 0.5333\n",
            "Epoch 598/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4817 - val_accuracy: 0.8824 - val_loss: 0.5148\n",
            "Epoch 599/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.5214\n",
            "Epoch 600/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5089\n",
            "Epoch 601/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5132\n",
            "Epoch 602/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4844 - val_accuracy: 0.8824 - val_loss: 0.5305\n",
            "Epoch 603/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5313\n",
            "Epoch 604/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5108\n",
            "Epoch 605/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5208\n",
            "Epoch 606/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5007\n",
            "Epoch 607/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5214\n",
            "Epoch 608/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5365\n",
            "Epoch 609/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5233\n",
            "Epoch 610/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5021\n",
            "Epoch 611/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5189\n",
            "Epoch 612/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5041\n",
            "Epoch 613/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5294\n",
            "Epoch 614/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5136\n",
            "Epoch 615/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5110\n",
            "Epoch 616/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5033\n",
            "Epoch 617/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4836 - val_accuracy: 0.8824 - val_loss: 0.5323\n",
            "Epoch 618/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5106\n",
            "Epoch 619/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5077\n",
            "Epoch 620/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5332\n",
            "Epoch 621/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4836 - val_accuracy: 0.8824 - val_loss: 0.5109\n",
            "Epoch 622/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5080\n",
            "Epoch 623/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7672 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5235\n",
            "Epoch 624/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5198\n",
            "Epoch 625/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7672 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.5081\n",
            "Epoch 626/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5286\n",
            "Epoch 627/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5028\n",
            "Epoch 628/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4842 - val_accuracy: 0.8824 - val_loss: 0.5366\n",
            "Epoch 629/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5082\n",
            "Epoch 630/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5105\n",
            "Epoch 631/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5153\n",
            "Epoch 632/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5227\n",
            "Epoch 633/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4861 - val_accuracy: 0.8824 - val_loss: 0.4908\n",
            "Epoch 634/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.5060\n",
            "Epoch 635/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5214\n",
            "Epoch 636/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5285\n",
            "Epoch 637/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5138\n",
            "Epoch 638/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5243\n",
            "Epoch 639/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5213\n",
            "Epoch 640/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4817 - val_accuracy: 0.8824 - val_loss: 0.5167\n",
            "Epoch 641/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4848 - val_accuracy: 0.8824 - val_loss: 0.5042\n",
            "Epoch 642/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7836 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5452\n",
            "Epoch 643/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.5278\n",
            "Epoch 644/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5120\n",
            "Epoch 645/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4817 - val_accuracy: 0.8824 - val_loss: 0.5135\n",
            "Epoch 646/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5164\n",
            "Epoch 647/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4843 - val_accuracy: 0.8824 - val_loss: 0.5338\n",
            "Epoch 648/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7705 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5078\n",
            "Epoch 649/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5159\n",
            "Epoch 650/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5016\n",
            "Epoch 651/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5076\n",
            "Epoch 652/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5241\n",
            "Epoch 653/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4845 - val_accuracy: 0.8824 - val_loss: 0.5459\n",
            "Epoch 654/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4836 - val_accuracy: 0.8824 - val_loss: 0.5155\n",
            "Epoch 655/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5198\n",
            "Epoch 656/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5247\n",
            "Epoch 657/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5225\n",
            "Epoch 658/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5168\n",
            "Epoch 659/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5137\n",
            "Epoch 660/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4855 - val_accuracy: 0.8824 - val_loss: 0.5397\n",
            "Epoch 661/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4854 - val_accuracy: 0.8824 - val_loss: 0.5181\n",
            "Epoch 662/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7836 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5069\n",
            "Epoch 663/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5222\n",
            "Epoch 664/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4841 - val_accuracy: 0.8824 - val_loss: 0.5082\n",
            "Epoch 665/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5216\n",
            "Epoch 666/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5279\n",
            "Epoch 667/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5074\n",
            "Epoch 668/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5185\n",
            "Epoch 669/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5258\n",
            "Epoch 670/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4841 - val_accuracy: 0.8824 - val_loss: 0.5305\n",
            "Epoch 671/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5325\n",
            "Epoch 672/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5172\n",
            "Epoch 673/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5161\n",
            "Epoch 674/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5214\n",
            "Epoch 675/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.5138\n",
            "Epoch 676/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5081\n",
            "Epoch 677/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7672 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5195\n",
            "Epoch 678/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4842 - val_accuracy: 0.8824 - val_loss: 0.5205\n",
            "Epoch 679/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5285\n",
            "Epoch 680/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5052\n",
            "Epoch 681/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5218\n",
            "Epoch 682/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5122\n",
            "Epoch 683/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7869 - loss: 0.4842 - val_accuracy: 0.8824 - val_loss: 0.5279\n",
            "Epoch 684/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5277\n",
            "Epoch 685/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5174\n",
            "Epoch 686/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5186\n",
            "Epoch 687/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5324\n",
            "Epoch 688/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5131\n",
            "Epoch 689/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5321\n",
            "Epoch 690/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5142\n",
            "Epoch 691/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5275\n",
            "Epoch 692/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4857 - val_accuracy: 0.8824 - val_loss: 0.5032\n",
            "Epoch 693/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5223\n",
            "Epoch 694/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7836 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5497\n",
            "Epoch 695/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5214\n",
            "Epoch 696/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.5149\n",
            "Epoch 697/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5144\n",
            "Epoch 698/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4860 - val_accuracy: 0.8824 - val_loss: 0.5173\n",
            "Epoch 699/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4835 - val_accuracy: 0.8824 - val_loss: 0.5105\n",
            "Epoch 700/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5212\n",
            "Epoch 701/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7672 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5325\n",
            "Epoch 702/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5238\n",
            "Epoch 703/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4817 - val_accuracy: 0.8824 - val_loss: 0.5079\n",
            "Epoch 704/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7836 - loss: 0.4861 - val_accuracy: 0.8824 - val_loss: 0.5380\n",
            "Epoch 705/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.5252\n",
            "Epoch 706/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5223\n",
            "Epoch 707/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4841 - val_accuracy: 0.8824 - val_loss: 0.5358\n",
            "Epoch 708/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5405\n",
            "Epoch 709/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5372\n",
            "Epoch 710/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5277\n",
            "Epoch 711/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4837 - val_accuracy: 0.8824 - val_loss: 0.5080\n",
            "Epoch 712/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5240\n",
            "Epoch 713/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5177\n",
            "Epoch 714/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5125\n",
            "Epoch 715/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5218\n",
            "Epoch 716/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5215\n",
            "Epoch 717/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7672 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5190\n",
            "Epoch 718/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5136\n",
            "Epoch 719/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5445\n",
            "Epoch 720/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5235\n",
            "Epoch 721/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5352\n",
            "Epoch 722/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5155\n",
            "Epoch 723/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5291\n",
            "Epoch 724/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5265\n",
            "Epoch 725/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5376\n",
            "Epoch 726/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4851 - val_accuracy: 0.8824 - val_loss: 0.5415\n",
            "Epoch 727/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7672 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5076\n",
            "Epoch 728/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4817 - val_accuracy: 0.8824 - val_loss: 0.5228\n",
            "Epoch 729/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5225\n",
            "Epoch 730/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4858 - val_accuracy: 0.8824 - val_loss: 0.5076\n",
            "Epoch 731/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5183\n",
            "Epoch 732/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5255\n",
            "Epoch 733/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5248\n",
            "Epoch 734/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5375\n",
            "Epoch 735/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7639 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5068\n",
            "Epoch 736/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5141\n",
            "Epoch 737/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5137\n",
            "Epoch 738/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7770 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5089\n",
            "Epoch 739/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5228\n",
            "Epoch 740/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5398\n",
            "Epoch 741/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5394\n",
            "Epoch 742/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7672 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5183\n",
            "Epoch 743/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7705 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5186\n",
            "Epoch 744/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5150\n",
            "Epoch 745/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5119\n",
            "Epoch 746/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4842 - val_accuracy: 0.8824 - val_loss: 0.5275\n",
            "Epoch 747/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7836 - loss: 0.4850 - val_accuracy: 0.8824 - val_loss: 0.5475\n",
            "Epoch 748/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5412\n",
            "Epoch 749/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5155\n",
            "Epoch 750/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5222\n",
            "Epoch 751/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5157\n",
            "Epoch 752/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5009\n",
            "Epoch 753/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5353\n",
            "Epoch 754/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7672 - loss: 0.4843 - val_accuracy: 0.8824 - val_loss: 0.5274\n",
            "Epoch 755/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7770 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5089\n",
            "Epoch 756/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4835 - val_accuracy: 0.8824 - val_loss: 0.5368\n",
            "Epoch 757/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5204\n",
            "Epoch 758/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5471\n",
            "Epoch 759/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5339\n",
            "Epoch 760/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7770 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5333\n",
            "Epoch 761/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7672 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5176\n",
            "Epoch 762/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4848 - val_accuracy: 0.8824 - val_loss: 0.5424\n",
            "Epoch 763/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5153\n",
            "Epoch 764/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5164\n",
            "Epoch 765/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5063\n",
            "Epoch 766/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7639 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5177\n",
            "Epoch 767/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5347\n",
            "Epoch 768/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5325\n",
            "Epoch 769/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7639 - loss: 0.4872 - val_accuracy: 0.8824 - val_loss: 0.5417\n",
            "Epoch 770/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5363\n",
            "Epoch 771/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5407\n",
            "Epoch 772/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5363\n",
            "Epoch 773/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7738 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5276\n",
            "Epoch 774/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5258\n",
            "Epoch 775/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5120\n",
            "Epoch 776/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5322\n",
            "Epoch 777/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5179\n",
            "Epoch 778/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5343\n",
            "Epoch 779/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5131\n",
            "Epoch 780/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4850 - val_accuracy: 0.8824 - val_loss: 0.5237\n",
            "Epoch 781/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.5366\n",
            "Epoch 782/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5254\n",
            "Epoch 783/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5179\n",
            "Epoch 784/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7738 - loss: 0.4840 - val_accuracy: 0.8824 - val_loss: 0.5103\n",
            "Epoch 785/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7738 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5060\n",
            "Epoch 786/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4861 - val_accuracy: 0.8824 - val_loss: 0.5142\n",
            "Epoch 787/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7738 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5284\n",
            "Epoch 788/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5368\n",
            "Epoch 789/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7672 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5162\n",
            "Epoch 790/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4854 - val_accuracy: 0.8824 - val_loss: 0.5164\n",
            "Epoch 791/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5327\n",
            "Epoch 792/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5530\n",
            "Epoch 793/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5273\n",
            "Epoch 794/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5282\n",
            "Epoch 795/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5463\n",
            "Epoch 796/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7705 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5118\n",
            "Epoch 797/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5234\n",
            "Epoch 798/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5220\n",
            "Epoch 799/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5186\n",
            "Epoch 800/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7738 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5190\n",
            "Epoch 801/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7770 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5127\n",
            "Epoch 802/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5256\n",
            "Epoch 803/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5139\n",
            "Epoch 804/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5118\n",
            "Epoch 805/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7705 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5242\n",
            "Epoch 806/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5320\n",
            "Epoch 807/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5124\n",
            "Epoch 808/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7738 - loss: 0.4835 - val_accuracy: 0.8824 - val_loss: 0.5147\n",
            "Epoch 809/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4837 - val_accuracy: 0.8824 - val_loss: 0.5314\n",
            "Epoch 810/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5157\n",
            "Epoch 811/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5226\n",
            "Epoch 812/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5158\n",
            "Epoch 813/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5209\n",
            "Epoch 814/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5377\n",
            "Epoch 815/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5345\n",
            "Epoch 816/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5216\n",
            "Epoch 817/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5183\n",
            "Epoch 818/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5129\n",
            "Epoch 819/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5260\n",
            "Epoch 820/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5348\n",
            "Epoch 821/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5193\n",
            "Epoch 822/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5297\n",
            "Epoch 823/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7770 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5402\n",
            "Epoch 824/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5231\n",
            "Epoch 825/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5178\n",
            "Epoch 826/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5232\n",
            "Epoch 827/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5425\n",
            "Epoch 828/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5285\n",
            "Epoch 829/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4817 - val_accuracy: 0.8824 - val_loss: 0.5284\n",
            "Epoch 830/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5427\n",
            "Epoch 831/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5337\n",
            "Epoch 832/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5222\n",
            "Epoch 833/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5266\n",
            "Epoch 834/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.5128\n",
            "Epoch 835/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7639 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5283\n",
            "Epoch 836/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5258\n",
            "Epoch 837/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5341\n",
            "Epoch 838/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5251\n",
            "Epoch 839/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5325\n",
            "Epoch 840/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5231\n",
            "Epoch 841/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5244\n",
            "Epoch 842/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4847 - val_accuracy: 0.8824 - val_loss: 0.5533\n",
            "Epoch 843/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7639 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5280\n",
            "Epoch 844/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5317\n",
            "Epoch 845/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5201\n",
            "Epoch 846/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5444\n",
            "Epoch 847/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5142\n",
            "Epoch 848/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5229\n",
            "Epoch 849/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5373\n",
            "Epoch 850/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7607 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5202\n",
            "Epoch 851/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5200\n",
            "Epoch 852/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5172\n",
            "Epoch 853/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5144\n",
            "Epoch 854/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5403\n",
            "Epoch 855/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5102\n",
            "Epoch 856/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5095\n",
            "Epoch 857/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5271\n",
            "Epoch 858/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5244\n",
            "Epoch 859/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5262\n",
            "Epoch 860/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5333\n",
            "Epoch 861/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7672 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.5234\n",
            "Epoch 862/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5416\n",
            "Epoch 863/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5390\n",
            "Epoch 864/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5130\n",
            "Epoch 865/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5438\n",
            "Epoch 866/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7836 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5386\n",
            "Epoch 867/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5105\n",
            "Epoch 868/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7836 - loss: 0.4836 - val_accuracy: 0.8824 - val_loss: 0.5279\n",
            "Epoch 869/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7672 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5176\n",
            "Epoch 870/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5395\n",
            "Epoch 871/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5274\n",
            "Epoch 872/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5169\n",
            "Epoch 873/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5241\n",
            "Epoch 874/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5252\n",
            "Epoch 875/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5264\n",
            "Epoch 876/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5186\n",
            "Epoch 877/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7836 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5291\n",
            "Epoch 878/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7836 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.5411\n",
            "Epoch 879/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5301\n",
            "Epoch 880/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4845 - val_accuracy: 0.8824 - val_loss: 0.5212\n",
            "Epoch 881/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5284\n",
            "Epoch 882/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5171\n",
            "Epoch 883/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5249\n",
            "Epoch 884/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5320\n",
            "Epoch 885/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5243\n",
            "Epoch 886/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5193\n",
            "Epoch 887/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5258\n",
            "Epoch 888/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5276\n",
            "Epoch 889/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5245\n",
            "Epoch 890/2000\n",
            "61/61 - 9s - 143ms/step - accuracy: 0.7705 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5286\n",
            "Epoch 891/2000\n",
            "61/61 - 9s - 143ms/step - accuracy: 0.7705 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5221\n",
            "Epoch 892/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5216\n",
            "Epoch 893/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5147\n",
            "Epoch 894/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5326\n",
            "Epoch 895/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7639 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5152\n",
            "Epoch 896/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5111\n",
            "Epoch 897/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5388\n",
            "Epoch 898/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5423\n",
            "Epoch 899/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7672 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5315\n",
            "Epoch 900/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4836 - val_accuracy: 0.8824 - val_loss: 0.5360\n",
            "Epoch 901/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5432\n",
            "Epoch 902/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7672 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5328\n",
            "Epoch 903/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7639 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5103\n",
            "Epoch 904/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5488\n",
            "Epoch 905/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.5198\n",
            "Epoch 906/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5179\n",
            "Epoch 907/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7672 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5221\n",
            "Epoch 908/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5207\n",
            "Epoch 909/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5288\n",
            "Epoch 910/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7672 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5263\n",
            "Epoch 911/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5349\n",
            "Epoch 912/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5189\n",
            "Epoch 913/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5421\n",
            "Epoch 914/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5381\n",
            "Epoch 915/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5311\n",
            "Epoch 916/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5355\n",
            "Epoch 917/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5457\n",
            "Epoch 918/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5292\n",
            "Epoch 919/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5132\n",
            "Epoch 920/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5379\n",
            "Epoch 921/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5303\n",
            "Epoch 922/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7672 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5284\n",
            "Epoch 923/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7770 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5205\n",
            "Epoch 924/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5254\n",
            "Epoch 925/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5223\n",
            "Epoch 926/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5314\n",
            "Epoch 927/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5199\n",
            "Epoch 928/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5395\n",
            "Epoch 929/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5337\n",
            "Epoch 930/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5318\n",
            "Epoch 931/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5368\n",
            "Epoch 932/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5279\n",
            "Epoch 933/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7672 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5373\n",
            "Epoch 934/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5333\n",
            "Epoch 935/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7672 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5274\n",
            "Epoch 936/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5148\n",
            "Epoch 937/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4817 - val_accuracy: 0.8824 - val_loss: 0.5184\n",
            "Epoch 938/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5211\n",
            "Epoch 939/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5339\n",
            "Epoch 940/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5374\n",
            "Epoch 941/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5356\n",
            "Epoch 942/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5282\n",
            "Epoch 943/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5232\n",
            "Epoch 944/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7672 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5234\n",
            "Epoch 945/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4817 - val_accuracy: 0.8824 - val_loss: 0.5493\n",
            "Epoch 946/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5267\n",
            "Epoch 947/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5412\n",
            "Epoch 948/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5306\n",
            "Epoch 949/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5214\n",
            "Epoch 950/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5245\n",
            "Epoch 951/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7836 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5288\n",
            "Epoch 952/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7869 - loss: 0.4835 - val_accuracy: 0.8824 - val_loss: 0.5372\n",
            "Epoch 953/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5352\n",
            "Epoch 954/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5287\n",
            "Epoch 955/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5406\n",
            "Epoch 956/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5199\n",
            "Epoch 957/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5279\n",
            "Epoch 958/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7902 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5536\n",
            "Epoch 959/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5245\n",
            "Epoch 960/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7836 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5139\n",
            "Epoch 961/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5279\n",
            "Epoch 962/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5253\n",
            "Epoch 963/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5331\n",
            "Epoch 964/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5262\n",
            "Epoch 965/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5216\n",
            "Epoch 966/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5271\n",
            "Epoch 967/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5337\n",
            "Epoch 968/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4835 - val_accuracy: 0.8824 - val_loss: 0.5335\n",
            "Epoch 969/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7836 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5240\n",
            "Epoch 970/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5299\n",
            "Epoch 971/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5152\n",
            "Epoch 972/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5195\n",
            "Epoch 973/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5214\n",
            "Epoch 974/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5233\n",
            "Epoch 975/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7836 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5409\n",
            "Epoch 976/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5184\n",
            "Epoch 977/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5480\n",
            "Epoch 978/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5195\n",
            "Epoch 979/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5410\n",
            "Epoch 980/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5200\n",
            "Epoch 981/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5369\n",
            "Epoch 982/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5229\n",
            "Epoch 983/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5304\n",
            "Epoch 984/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5301\n",
            "Epoch 985/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5229\n",
            "Epoch 986/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5297\n",
            "Epoch 987/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5381\n",
            "Epoch 988/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5176\n",
            "Epoch 989/2000\n",
            "61/61 - 13s - 209ms/step - accuracy: 0.7770 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5299\n",
            "Epoch 990/2000\n",
            "61/61 - 10s - 158ms/step - accuracy: 0.7803 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5227\n",
            "Epoch 991/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5347\n",
            "Epoch 992/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5168\n",
            "Epoch 993/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5406\n",
            "Epoch 994/2000\n",
            "61/61 - 922s - 15s/step - accuracy: 0.7705 - loss: 0.4843 - val_accuracy: 0.8824 - val_loss: 0.5273\n",
            "Epoch 995/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5448\n",
            "Epoch 996/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5298\n",
            "Epoch 997/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4831 - val_accuracy: 0.8824 - val_loss: 0.5278\n",
            "Epoch 998/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5444\n",
            "Epoch 999/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5310\n",
            "Epoch 1000/2000\n",
            "61/61 - 476s - 8s/step - accuracy: 0.7803 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.5219\n",
            "Epoch 1001/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5212\n",
            "Epoch 1002/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5297\n",
            "Epoch 1003/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5213\n",
            "Epoch 1004/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7770 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5472\n",
            "Epoch 1005/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7705 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5315\n",
            "Epoch 1006/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5261\n",
            "Epoch 1007/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5293\n",
            "Epoch 1008/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5338\n",
            "Epoch 1009/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7672 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5154\n",
            "Epoch 1010/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5178\n",
            "Epoch 1011/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5301\n",
            "Epoch 1012/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5323\n",
            "Epoch 1013/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5237\n",
            "Epoch 1014/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7770 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5194\n",
            "Epoch 1015/2000\n",
            "61/61 - 10s - 156ms/step - accuracy: 0.7738 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5448\n",
            "Epoch 1016/2000\n",
            "61/61 - 10s - 161ms/step - accuracy: 0.7738 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5345\n",
            "Epoch 1017/2000\n",
            "61/61 - 10s - 165ms/step - accuracy: 0.7803 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5405\n",
            "Epoch 1018/2000\n",
            "61/61 - 10s - 166ms/step - accuracy: 0.7803 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5431\n",
            "Epoch 1019/2000\n",
            "61/61 - 10s - 168ms/step - accuracy: 0.7803 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5360\n",
            "Epoch 1020/2000\n",
            "61/61 - 10s - 168ms/step - accuracy: 0.7672 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5282\n",
            "Epoch 1021/2000\n",
            "61/61 - 12s - 194ms/step - accuracy: 0.7803 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5284\n",
            "Epoch 1022/2000\n",
            "61/61 - 12s - 199ms/step - accuracy: 0.7738 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5182\n",
            "Epoch 1023/2000\n",
            "61/61 - 926s - 15s/step - accuracy: 0.7836 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5324\n",
            "Epoch 1024/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4817 - val_accuracy: 0.8824 - val_loss: 0.5245\n",
            "Epoch 1025/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5277\n",
            "Epoch 1026/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7770 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5171\n",
            "Epoch 1027/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5365\n",
            "Epoch 1028/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5147\n",
            "Epoch 1029/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5267\n",
            "Epoch 1030/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7770 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5128\n",
            "Epoch 1031/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7738 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5546\n",
            "Epoch 1032/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5313\n",
            "Epoch 1033/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5216\n",
            "Epoch 1034/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5226\n",
            "Epoch 1035/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5267\n",
            "Epoch 1036/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7738 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5426\n",
            "Epoch 1037/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5230\n",
            "Epoch 1038/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5399\n",
            "Epoch 1039/2000\n",
            "61/61 - 9s - 155ms/step - accuracy: 0.7770 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5246\n",
            "Epoch 1040/2000\n",
            "61/61 - 10s - 160ms/step - accuracy: 0.7672 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5153\n",
            "Epoch 1041/2000\n",
            "61/61 - 10s - 164ms/step - accuracy: 0.7738 - loss: 0.4796 - val_accuracy: 0.8824 - val_loss: 0.5297\n",
            "Epoch 1042/2000\n",
            "61/61 - 10s - 165ms/step - accuracy: 0.7738 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5336\n",
            "Epoch 1043/2000\n",
            "61/61 - 10s - 167ms/step - accuracy: 0.7803 - loss: 0.4850 - val_accuracy: 0.8824 - val_loss: 0.5139\n",
            "Epoch 1044/2000\n",
            "61/61 - 10s - 167ms/step - accuracy: 0.7803 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5293\n",
            "Epoch 1045/2000\n",
            "61/61 - 10s - 168ms/step - accuracy: 0.7803 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5144\n",
            "Epoch 1046/2000\n",
            "61/61 - 12s - 192ms/step - accuracy: 0.7705 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5337\n",
            "Epoch 1047/2000\n",
            "61/61 - 12s - 200ms/step - accuracy: 0.7803 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5357\n",
            "Epoch 1048/2000\n",
            "61/61 - 521s - 9s/step - accuracy: 0.7738 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5200\n",
            "Epoch 1049/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5197\n",
            "Epoch 1050/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5281\n",
            "Epoch 1051/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5236\n",
            "Epoch 1052/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5315\n",
            "Epoch 1053/2000\n",
            "61/61 - 907s - 15s/step - accuracy: 0.7738 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5281\n",
            "Epoch 1054/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5322\n",
            "Epoch 1055/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5388\n",
            "Epoch 1056/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5292\n",
            "Epoch 1057/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5323\n",
            "Epoch 1058/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4841 - val_accuracy: 0.8824 - val_loss: 0.5182\n",
            "Epoch 1059/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5341\n",
            "Epoch 1060/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5198\n",
            "Epoch 1061/2000\n",
            "61/61 - 765s - 13s/step - accuracy: 0.7738 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5247\n",
            "Epoch 1062/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5254\n",
            "Epoch 1063/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5223\n",
            "Epoch 1064/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7672 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5142\n",
            "Epoch 1065/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5401\n",
            "Epoch 1066/2000\n",
            "61/61 - 953s - 16s/step - accuracy: 0.7803 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5374\n",
            "Epoch 1067/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7770 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5248\n",
            "Epoch 1068/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7672 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5230\n",
            "Epoch 1069/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5359\n",
            "Epoch 1070/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5425\n",
            "Epoch 1071/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5303\n",
            "Epoch 1072/2000\n",
            "61/61 - 588s - 10s/step - accuracy: 0.7705 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5236\n",
            "Epoch 1073/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7770 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5259\n",
            "Epoch 1074/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5352\n",
            "Epoch 1075/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5240\n",
            "Epoch 1076/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5312\n",
            "Epoch 1077/2000\n",
            "61/61 - 10s - 163ms/step - accuracy: 0.7803 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5245\n",
            "Epoch 1078/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5234\n",
            "Epoch 1079/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5165\n",
            "Epoch 1080/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5409\n",
            "Epoch 1081/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.5466\n",
            "Epoch 1082/2000\n",
            "61/61 - 16s - 259ms/step - accuracy: 0.7738 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5183\n",
            "Epoch 1083/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5178\n",
            "Epoch 1084/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5241\n",
            "Epoch 1085/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5271\n",
            "Epoch 1086/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5382\n",
            "Epoch 1087/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5352\n",
            "Epoch 1088/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5233\n",
            "Epoch 1089/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7836 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5168\n",
            "Epoch 1090/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5193\n",
            "Epoch 1091/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4844 - val_accuracy: 0.8824 - val_loss: 0.5257\n",
            "Epoch 1092/2000\n",
            "61/61 - 10s - 156ms/step - accuracy: 0.7770 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5404\n",
            "Epoch 1093/2000\n",
            "61/61 - 10s - 159ms/step - accuracy: 0.7738 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5119\n",
            "Epoch 1094/2000\n",
            "61/61 - 10s - 163ms/step - accuracy: 0.7803 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5268\n",
            "Epoch 1095/2000\n",
            "61/61 - 10s - 165ms/step - accuracy: 0.7803 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5185\n",
            "Epoch 1096/2000\n",
            "61/61 - 10s - 166ms/step - accuracy: 0.7803 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5330\n",
            "Epoch 1097/2000\n",
            "61/61 - 10s - 166ms/step - accuracy: 0.7803 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5264\n",
            "Epoch 1098/2000\n",
            "61/61 - 10s - 167ms/step - accuracy: 0.7803 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.5426\n",
            "Epoch 1099/2000\n",
            "61/61 - 10s - 167ms/step - accuracy: 0.7803 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5245\n",
            "Epoch 1100/2000\n",
            "61/61 - 10s - 167ms/step - accuracy: 0.7803 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5327\n",
            "Epoch 1101/2000\n",
            "61/61 - 10s - 167ms/step - accuracy: 0.7738 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5322\n",
            "Epoch 1102/2000\n",
            "61/61 - 12s - 189ms/step - accuracy: 0.7705 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5184\n",
            "Epoch 1103/2000\n",
            "61/61 - 12s - 197ms/step - accuracy: 0.7738 - loss: 0.4817 - val_accuracy: 0.8824 - val_loss: 0.5221\n",
            "Epoch 1104/2000\n",
            "61/61 - 12s - 199ms/step - accuracy: 0.7803 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5126\n",
            "Epoch 1105/2000\n",
            "61/61 - 13s - 205ms/step - accuracy: 0.7738 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5187\n",
            "Epoch 1106/2000\n",
            "61/61 - 104s - 2s/step - accuracy: 0.7836 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5254\n",
            "Epoch 1107/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5367\n",
            "Epoch 1108/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5406\n",
            "Epoch 1109/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5175\n",
            "Epoch 1110/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5150\n",
            "Epoch 1111/2000\n",
            "61/61 - 152s - 2s/step - accuracy: 0.7770 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5293\n",
            "Epoch 1112/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5156\n",
            "Epoch 1113/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5239\n",
            "Epoch 1114/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5228\n",
            "Epoch 1115/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5068\n",
            "Epoch 1116/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5183\n",
            "Epoch 1117/2000\n",
            "61/61 - 575s - 9s/step - accuracy: 0.7803 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5143\n",
            "Epoch 1118/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5258\n",
            "Epoch 1119/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5232\n",
            "Epoch 1120/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5238\n",
            "Epoch 1121/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5283\n",
            "Epoch 1122/2000\n",
            "61/61 - 125s - 2s/step - accuracy: 0.7705 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5255\n",
            "Epoch 1123/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7836 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5185\n",
            "Epoch 1124/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7836 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5461\n",
            "Epoch 1125/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7639 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5164\n",
            "Epoch 1126/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7639 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5409\n",
            "Epoch 1127/2000\n",
            "61/61 - 576s - 9s/step - accuracy: 0.7803 - loss: 0.4840 - val_accuracy: 0.8824 - val_loss: 0.5541\n",
            "Epoch 1128/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5314\n",
            "Epoch 1129/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7639 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5312\n",
            "Epoch 1130/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7607 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5180\n",
            "Epoch 1131/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5218\n",
            "Epoch 1132/2000\n",
            "61/61 - 9s - 144ms/step - accuracy: 0.7770 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5297\n",
            "Epoch 1133/2000\n",
            "61/61 - 16s - 259ms/step - accuracy: 0.7705 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5219\n",
            "Epoch 1134/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5152\n",
            "Epoch 1135/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5268\n",
            "Epoch 1136/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5320\n",
            "Epoch 1137/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5271\n",
            "Epoch 1138/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5174\n",
            "Epoch 1139/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5362\n",
            "Epoch 1140/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5269\n",
            "Epoch 1141/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4817 - val_accuracy: 0.8824 - val_loss: 0.5383\n",
            "Epoch 1142/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5341\n",
            "Epoch 1143/2000\n",
            "61/61 - 9s - 150ms/step - accuracy: 0.7803 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5251\n",
            "Epoch 1144/2000\n",
            "61/61 - 10s - 160ms/step - accuracy: 0.7803 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5162\n",
            "Epoch 1145/2000\n",
            "61/61 - 10s - 164ms/step - accuracy: 0.7770 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5316\n",
            "Epoch 1146/2000\n",
            "61/61 - 10s - 167ms/step - accuracy: 0.7738 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5265\n",
            "Epoch 1147/2000\n",
            "61/61 - 10s - 167ms/step - accuracy: 0.7770 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5220\n",
            "Epoch 1148/2000\n",
            "61/61 - 10s - 169ms/step - accuracy: 0.7803 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5280\n",
            "Epoch 1149/2000\n",
            "61/61 - 10s - 170ms/step - accuracy: 0.7705 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5168\n",
            "Epoch 1150/2000\n",
            "61/61 - 11s - 179ms/step - accuracy: 0.7672 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5200\n",
            "Epoch 1151/2000\n",
            "61/61 - 12s - 199ms/step - accuracy: 0.7738 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5342\n",
            "Epoch 1152/2000\n",
            "61/61 - 12s - 202ms/step - accuracy: 0.7738 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5216\n",
            "Epoch 1153/2000\n",
            "61/61 - 341s - 6s/step - accuracy: 0.7770 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5193\n",
            "Epoch 1154/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5342\n",
            "Epoch 1155/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5302\n",
            "Epoch 1156/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5345\n",
            "Epoch 1157/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7705 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5221\n",
            "Epoch 1158/2000\n",
            "61/61 - 498s - 8s/step - accuracy: 0.7836 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5225\n",
            "Epoch 1159/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5338\n",
            "Epoch 1160/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7770 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5308\n",
            "Epoch 1161/2000\n",
            "61/61 - 9s - 150ms/step - accuracy: 0.7705 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5202\n",
            "Epoch 1162/2000\n",
            "61/61 - 9s - 151ms/step - accuracy: 0.7770 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5306\n",
            "Epoch 1163/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5427\n",
            "Epoch 1164/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5276\n",
            "Epoch 1165/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5317\n",
            "Epoch 1166/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5245\n",
            "Epoch 1167/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5179\n",
            "Epoch 1168/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7836 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5299\n",
            "Epoch 1169/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5342\n",
            "Epoch 1170/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5264\n",
            "Epoch 1171/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4792 - val_accuracy: 0.8824 - val_loss: 0.5339\n",
            "Epoch 1172/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5393\n",
            "Epoch 1173/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7836 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5345\n",
            "Epoch 1174/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5297\n",
            "Epoch 1175/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5255\n",
            "Epoch 1176/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5262\n",
            "Epoch 1177/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5233\n",
            "Epoch 1178/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5270\n",
            "Epoch 1179/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5255\n",
            "Epoch 1180/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5281\n",
            "Epoch 1181/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5167\n",
            "Epoch 1182/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5308\n",
            "Epoch 1183/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7639 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5352\n",
            "Epoch 1184/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5292\n",
            "Epoch 1185/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5381\n",
            "Epoch 1186/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5286\n",
            "Epoch 1187/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5165\n",
            "Epoch 1188/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5293\n",
            "Epoch 1189/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5300\n",
            "Epoch 1190/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5298\n",
            "Epoch 1191/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5299\n",
            "Epoch 1192/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5363\n",
            "Epoch 1193/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5258\n",
            "Epoch 1194/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5164\n",
            "Epoch 1195/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5217\n",
            "Epoch 1196/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5454\n",
            "Epoch 1197/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5236\n",
            "Epoch 1198/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5234\n",
            "Epoch 1199/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5118\n",
            "Epoch 1200/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7672 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5159\n",
            "Epoch 1201/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5194\n",
            "Epoch 1202/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5158\n",
            "Epoch 1203/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5192\n",
            "Epoch 1204/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5181\n",
            "Epoch 1205/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5233\n",
            "Epoch 1206/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5364\n",
            "Epoch 1207/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5115\n",
            "Epoch 1208/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4788 - val_accuracy: 0.8824 - val_loss: 0.5346\n",
            "Epoch 1209/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5324\n",
            "Epoch 1210/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5176\n",
            "Epoch 1211/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5237\n",
            "Epoch 1212/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7738 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5263\n",
            "Epoch 1213/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5312\n",
            "Epoch 1214/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4850 - val_accuracy: 0.8824 - val_loss: 0.5265\n",
            "Epoch 1215/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5283\n",
            "Epoch 1216/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5219\n",
            "Epoch 1217/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7770 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5223\n",
            "Epoch 1218/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5501\n",
            "Epoch 1219/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5297\n",
            "Epoch 1220/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5284\n",
            "Epoch 1221/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5136\n",
            "Epoch 1222/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5256\n",
            "Epoch 1223/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5303\n",
            "Epoch 1224/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5250\n",
            "Epoch 1225/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5318\n",
            "Epoch 1226/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5271\n",
            "Epoch 1227/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5250\n",
            "Epoch 1228/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5251\n",
            "Epoch 1229/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7869 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5379\n",
            "Epoch 1230/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5295\n",
            "Epoch 1231/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5326\n",
            "Epoch 1232/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5336\n",
            "Epoch 1233/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5302\n",
            "Epoch 1234/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5285\n",
            "Epoch 1235/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5250\n",
            "Epoch 1236/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5223\n",
            "Epoch 1237/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5175\n",
            "Epoch 1238/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5149\n",
            "Epoch 1239/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5229\n",
            "Epoch 1240/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5276\n",
            "Epoch 1241/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5231\n",
            "Epoch 1242/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5200\n",
            "Epoch 1243/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5316\n",
            "Epoch 1244/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5277\n",
            "Epoch 1245/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5207\n",
            "Epoch 1246/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5316\n",
            "Epoch 1247/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5341\n",
            "Epoch 1248/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7705 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5202\n",
            "Epoch 1249/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5360\n",
            "Epoch 1250/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5374\n",
            "Epoch 1251/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5245\n",
            "Epoch 1252/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7672 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5455\n",
            "Epoch 1253/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5195\n",
            "Epoch 1254/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5291\n",
            "Epoch 1255/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5222\n",
            "Epoch 1256/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5386\n",
            "Epoch 1257/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5223\n",
            "Epoch 1258/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4829 - val_accuracy: 0.8824 - val_loss: 0.5168\n",
            "Epoch 1259/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5165\n",
            "Epoch 1260/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5232\n",
            "Epoch 1261/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5214\n",
            "Epoch 1262/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5237\n",
            "Epoch 1263/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5316\n",
            "Epoch 1264/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5314\n",
            "Epoch 1265/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5371\n",
            "Epoch 1266/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5332\n",
            "Epoch 1267/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5283\n",
            "Epoch 1268/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5199\n",
            "Epoch 1269/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5244\n",
            "Epoch 1270/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5248\n",
            "Epoch 1271/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5394\n",
            "Epoch 1272/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7836 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5098\n",
            "Epoch 1273/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5264\n",
            "Epoch 1274/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7869 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5579\n",
            "Epoch 1275/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7803 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5420\n",
            "Epoch 1276/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5253\n",
            "Epoch 1277/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5166\n",
            "Epoch 1278/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5217\n",
            "Epoch 1279/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4837 - val_accuracy: 0.8824 - val_loss: 0.5083\n",
            "Epoch 1280/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4817 - val_accuracy: 0.8824 - val_loss: 0.5388\n",
            "Epoch 1281/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5397\n",
            "Epoch 1282/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5495\n",
            "Epoch 1283/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5331\n",
            "Epoch 1284/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5228\n",
            "Epoch 1285/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5373\n",
            "Epoch 1286/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5227\n",
            "Epoch 1287/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5284\n",
            "Epoch 1288/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5301\n",
            "Epoch 1289/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5239\n",
            "Epoch 1290/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5213\n",
            "Epoch 1291/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5256\n",
            "Epoch 1292/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5252\n",
            "Epoch 1293/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5122\n",
            "Epoch 1294/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5198\n",
            "Epoch 1295/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5345\n",
            "Epoch 1296/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5276\n",
            "Epoch 1297/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5212\n",
            "Epoch 1298/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5262\n",
            "Epoch 1299/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5207\n",
            "Epoch 1300/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5264\n",
            "Epoch 1301/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5317\n",
            "Epoch 1302/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5114\n",
            "Epoch 1303/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5272\n",
            "Epoch 1304/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5090\n",
            "Epoch 1305/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5165\n",
            "Epoch 1306/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5248\n",
            "Epoch 1307/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5209\n",
            "Epoch 1308/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7836 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5215\n",
            "Epoch 1309/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5248\n",
            "Epoch 1310/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5338\n",
            "Epoch 1311/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5259\n",
            "Epoch 1312/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5328\n",
            "Epoch 1313/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5284\n",
            "Epoch 1314/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7672 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5266\n",
            "Epoch 1315/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.5297\n",
            "Epoch 1316/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5254\n",
            "Epoch 1317/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5279\n",
            "Epoch 1318/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5237\n",
            "Epoch 1319/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5331\n",
            "Epoch 1320/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5190\n",
            "Epoch 1321/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5232\n",
            "Epoch 1322/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5263\n",
            "Epoch 1323/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5204\n",
            "Epoch 1324/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4792 - val_accuracy: 0.8824 - val_loss: 0.5201\n",
            "Epoch 1325/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4790 - val_accuracy: 0.8824 - val_loss: 0.5335\n",
            "Epoch 1326/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5424\n",
            "Epoch 1327/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5391\n",
            "Epoch 1328/2000\n",
            "61/61 - 9s - 151ms/step - accuracy: 0.7770 - loss: 0.4789 - val_accuracy: 0.8824 - val_loss: 0.5170\n",
            "Epoch 1329/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7639 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5234\n",
            "Epoch 1330/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5176\n",
            "Epoch 1331/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5462\n",
            "Epoch 1332/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5353\n",
            "Epoch 1333/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5186\n",
            "Epoch 1334/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5217\n",
            "Epoch 1335/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4796 - val_accuracy: 0.8824 - val_loss: 0.5204\n",
            "Epoch 1336/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7672 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5215\n",
            "Epoch 1337/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4793 - val_accuracy: 0.8824 - val_loss: 0.5272\n",
            "Epoch 1338/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5475\n",
            "Epoch 1339/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5348\n",
            "Epoch 1340/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5200\n",
            "Epoch 1341/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5218\n",
            "Epoch 1342/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5261\n",
            "Epoch 1343/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5233\n",
            "Epoch 1344/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5230\n",
            "Epoch 1345/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5302\n",
            "Epoch 1346/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7705 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5498\n",
            "Epoch 1347/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5257\n",
            "Epoch 1348/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5185\n",
            "Epoch 1349/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5281\n",
            "Epoch 1350/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4794 - val_accuracy: 0.8824 - val_loss: 0.5282\n",
            "Epoch 1351/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5157\n",
            "Epoch 1352/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5255\n",
            "Epoch 1353/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5297\n",
            "Epoch 1354/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5228\n",
            "Epoch 1355/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5237\n",
            "Epoch 1356/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5115\n",
            "Epoch 1357/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5291\n",
            "Epoch 1358/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5129\n",
            "Epoch 1359/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5305\n",
            "Epoch 1360/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5346\n",
            "Epoch 1361/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5304\n",
            "Epoch 1362/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5335\n",
            "Epoch 1363/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5287\n",
            "Epoch 1364/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5374\n",
            "Epoch 1365/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5269\n",
            "Epoch 1366/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5311\n",
            "Epoch 1367/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4793 - val_accuracy: 0.8824 - val_loss: 0.5227\n",
            "Epoch 1368/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5215\n",
            "Epoch 1369/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5405\n",
            "Epoch 1370/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5345\n",
            "Epoch 1371/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5225\n",
            "Epoch 1372/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5183\n",
            "Epoch 1373/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5224\n",
            "Epoch 1374/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5277\n",
            "Epoch 1375/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5250\n",
            "Epoch 1376/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5339\n",
            "Epoch 1377/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5075\n",
            "Epoch 1378/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5192\n",
            "Epoch 1379/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7836 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5347\n",
            "Epoch 1380/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5326\n",
            "Epoch 1381/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5071\n",
            "Epoch 1382/2000\n",
            "61/61 - 9s - 150ms/step - accuracy: 0.7770 - loss: 0.4817 - val_accuracy: 0.8824 - val_loss: 0.5225\n",
            "Epoch 1383/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5150\n",
            "Epoch 1384/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5189\n",
            "Epoch 1385/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5320\n",
            "Epoch 1386/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4817 - val_accuracy: 0.8824 - val_loss: 0.5283\n",
            "Epoch 1387/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5118\n",
            "Epoch 1388/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5281\n",
            "Epoch 1389/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5259\n",
            "Epoch 1390/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5298\n",
            "Epoch 1391/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7705 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5291\n",
            "Epoch 1392/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5379\n",
            "Epoch 1393/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5216\n",
            "Epoch 1394/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5299\n",
            "Epoch 1395/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5193\n",
            "Epoch 1396/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5301\n",
            "Epoch 1397/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7705 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5123\n",
            "Epoch 1398/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5361\n",
            "Epoch 1399/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7836 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5093\n",
            "Epoch 1400/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5379\n",
            "Epoch 1401/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5308\n",
            "Epoch 1402/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5227\n",
            "Epoch 1403/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5323\n",
            "Epoch 1404/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5288\n",
            "Epoch 1405/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5172\n",
            "Epoch 1406/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5320\n",
            "Epoch 1407/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5239\n",
            "Epoch 1408/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5227\n",
            "Epoch 1409/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5240\n",
            "Epoch 1410/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5156\n",
            "Epoch 1411/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5246\n",
            "Epoch 1412/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5216\n",
            "Epoch 1413/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7639 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5297\n",
            "Epoch 1414/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5280\n",
            "Epoch 1415/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5162\n",
            "Epoch 1416/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5302\n",
            "Epoch 1417/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5338\n",
            "Epoch 1418/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5265\n",
            "Epoch 1419/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5157\n",
            "Epoch 1420/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5157\n",
            "Epoch 1421/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5185\n",
            "Epoch 1422/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5129\n",
            "Epoch 1423/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7803 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5172\n",
            "Epoch 1424/2000\n",
            "61/61 - 9s - 150ms/step - accuracy: 0.7705 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5295\n",
            "Epoch 1425/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5371\n",
            "Epoch 1426/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5322\n",
            "Epoch 1427/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5191\n",
            "Epoch 1428/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5306\n",
            "Epoch 1429/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7836 - loss: 0.4817 - val_accuracy: 0.8824 - val_loss: 0.5377\n",
            "Epoch 1430/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5268\n",
            "Epoch 1431/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5179\n",
            "Epoch 1432/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5319\n",
            "Epoch 1433/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5201\n",
            "Epoch 1434/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7836 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5129\n",
            "Epoch 1435/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5173\n",
            "Epoch 1436/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4792 - val_accuracy: 0.8824 - val_loss: 0.5221\n",
            "Epoch 1437/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5266\n",
            "Epoch 1438/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.5256\n",
            "Epoch 1439/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5256\n",
            "Epoch 1440/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5227\n",
            "Epoch 1441/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5128\n",
            "Epoch 1442/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7836 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5197\n",
            "Epoch 1443/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5258\n",
            "Epoch 1444/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5265\n",
            "Epoch 1445/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5285\n",
            "Epoch 1446/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5306\n",
            "Epoch 1447/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4796 - val_accuracy: 0.8824 - val_loss: 0.5186\n",
            "Epoch 1448/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5281\n",
            "Epoch 1449/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5066\n",
            "Epoch 1450/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5248\n",
            "Epoch 1451/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5302\n",
            "Epoch 1452/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5362\n",
            "Epoch 1453/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5200\n",
            "Epoch 1454/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4792 - val_accuracy: 0.8824 - val_loss: 0.5255\n",
            "Epoch 1455/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5294\n",
            "Epoch 1456/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5225\n",
            "Epoch 1457/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4796 - val_accuracy: 0.8824 - val_loss: 0.5238\n",
            "Epoch 1458/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5353\n",
            "Epoch 1459/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5311\n",
            "Epoch 1460/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5257\n",
            "Epoch 1461/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5199\n",
            "Epoch 1462/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5268\n",
            "Epoch 1463/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4796 - val_accuracy: 0.8824 - val_loss: 0.5463\n",
            "Epoch 1464/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5247\n",
            "Epoch 1465/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4790 - val_accuracy: 0.8824 - val_loss: 0.5284\n",
            "Epoch 1466/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5408\n",
            "Epoch 1467/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7672 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5206\n",
            "Epoch 1468/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5268\n",
            "Epoch 1469/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5229\n",
            "Epoch 1470/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5262\n",
            "Epoch 1471/2000\n",
            "61/61 - 9s - 150ms/step - accuracy: 0.7738 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5237\n",
            "Epoch 1472/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7836 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5182\n",
            "Epoch 1473/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5245\n",
            "Epoch 1474/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5242\n",
            "Epoch 1475/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4793 - val_accuracy: 0.8824 - val_loss: 0.5264\n",
            "Epoch 1476/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5282\n",
            "Epoch 1477/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5192\n",
            "Epoch 1478/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4796 - val_accuracy: 0.8824 - val_loss: 0.5311\n",
            "Epoch 1479/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4817 - val_accuracy: 0.8824 - val_loss: 0.5288\n",
            "Epoch 1480/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5214\n",
            "Epoch 1481/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5238\n",
            "Epoch 1482/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5144\n",
            "Epoch 1483/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5298\n",
            "Epoch 1484/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5312\n",
            "Epoch 1485/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5383\n",
            "Epoch 1486/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5255\n",
            "Epoch 1487/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5354\n",
            "Epoch 1488/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4791 - val_accuracy: 0.8824 - val_loss: 0.5182\n",
            "Epoch 1489/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5263\n",
            "Epoch 1490/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5330\n",
            "Epoch 1491/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5277\n",
            "Epoch 1492/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5231\n",
            "Epoch 1493/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5165\n",
            "Epoch 1494/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5270\n",
            "Epoch 1495/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5175\n",
            "Epoch 1496/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5233\n",
            "Epoch 1497/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5290\n",
            "Epoch 1498/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7705 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5206\n",
            "Epoch 1499/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5224\n",
            "Epoch 1500/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5313\n",
            "Epoch 1501/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4792 - val_accuracy: 0.8824 - val_loss: 0.5227\n",
            "Epoch 1502/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5340\n",
            "Epoch 1503/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5297\n",
            "Epoch 1504/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7836 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5302\n",
            "Epoch 1505/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5258\n",
            "Epoch 1506/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4792 - val_accuracy: 0.8824 - val_loss: 0.5132\n",
            "Epoch 1507/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5192\n",
            "Epoch 1508/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4794 - val_accuracy: 0.8824 - val_loss: 0.5269\n",
            "Epoch 1509/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5274\n",
            "Epoch 1510/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4794 - val_accuracy: 0.8824 - val_loss: 0.5271\n",
            "Epoch 1511/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5315\n",
            "Epoch 1512/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5197\n",
            "Epoch 1513/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5283\n",
            "Epoch 1514/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4794 - val_accuracy: 0.8824 - val_loss: 0.5272\n",
            "Epoch 1515/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5168\n",
            "Epoch 1516/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5194\n",
            "Epoch 1517/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5185\n",
            "Epoch 1518/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4817 - val_accuracy: 0.8824 - val_loss: 0.5290\n",
            "Epoch 1519/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5239\n",
            "Epoch 1520/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7836 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5244\n",
            "Epoch 1521/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5263\n",
            "Epoch 1522/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5174\n",
            "Epoch 1523/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5222\n",
            "Epoch 1524/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4794 - val_accuracy: 0.8824 - val_loss: 0.5406\n",
            "Epoch 1525/2000\n",
            "61/61 - 9s - 149ms/step - accuracy: 0.7738 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5370\n",
            "Epoch 1526/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4796 - val_accuracy: 0.8824 - val_loss: 0.5172\n",
            "Epoch 1527/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5154\n",
            "Epoch 1528/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5139\n",
            "Epoch 1529/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7836 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5200\n",
            "Epoch 1530/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5195\n",
            "Epoch 1531/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5199\n",
            "Epoch 1532/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5224\n",
            "Epoch 1533/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5374\n",
            "Epoch 1534/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5281\n",
            "Epoch 1535/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5216\n",
            "Epoch 1536/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7672 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5327\n",
            "Epoch 1537/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5157\n",
            "Epoch 1538/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5217\n",
            "Epoch 1539/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5223\n",
            "Epoch 1540/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5337\n",
            "Epoch 1541/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4787 - val_accuracy: 0.8824 - val_loss: 0.5200\n",
            "Epoch 1542/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7705 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5325\n",
            "Epoch 1543/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5258\n",
            "Epoch 1544/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5231\n",
            "Epoch 1545/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4792 - val_accuracy: 0.8824 - val_loss: 0.5240\n",
            "Epoch 1546/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5291\n",
            "Epoch 1547/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5189\n",
            "Epoch 1548/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7639 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5221\n",
            "Epoch 1549/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5313\n",
            "Epoch 1550/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5285\n",
            "Epoch 1551/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4796 - val_accuracy: 0.8824 - val_loss: 0.5190\n",
            "Epoch 1552/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4793 - val_accuracy: 0.8824 - val_loss: 0.5277\n",
            "Epoch 1553/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5220\n",
            "Epoch 1554/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5265\n",
            "Epoch 1555/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5232\n",
            "Epoch 1556/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4796 - val_accuracy: 0.8824 - val_loss: 0.5230\n",
            "Epoch 1557/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5192\n",
            "Epoch 1558/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5156\n",
            "Epoch 1559/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5342\n",
            "Epoch 1560/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5236\n",
            "Epoch 1561/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5310\n",
            "Epoch 1562/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5305\n",
            "Epoch 1563/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5170\n",
            "Epoch 1564/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4794 - val_accuracy: 0.8824 - val_loss: 0.5256\n",
            "Epoch 1565/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5251\n",
            "Epoch 1566/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5215\n",
            "Epoch 1567/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5254\n",
            "Epoch 1568/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5316\n",
            "Epoch 1569/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4817 - val_accuracy: 0.8824 - val_loss: 0.5169\n",
            "Epoch 1570/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5286\n",
            "Epoch 1571/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5179\n",
            "Epoch 1572/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5196\n",
            "Epoch 1573/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5216\n",
            "Epoch 1574/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.5195\n",
            "Epoch 1575/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5140\n",
            "Epoch 1576/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4849 - val_accuracy: 0.8824 - val_loss: 0.5179\n",
            "Epoch 1577/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5187\n",
            "Epoch 1578/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5162\n",
            "Epoch 1579/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5190\n",
            "Epoch 1580/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5110\n",
            "Epoch 1581/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7869 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5227\n",
            "Epoch 1582/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4793 - val_accuracy: 0.8824 - val_loss: 0.5240\n",
            "Epoch 1583/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7705 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5161\n",
            "Epoch 1584/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5445\n",
            "Epoch 1585/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5291\n",
            "Epoch 1586/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5434\n",
            "Epoch 1587/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7607 - loss: 0.4869 - val_accuracy: 0.8824 - val_loss: 0.5060\n",
            "Epoch 1588/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5259\n",
            "Epoch 1589/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4843 - val_accuracy: 0.8824 - val_loss: 0.5390\n",
            "Epoch 1590/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4841 - val_accuracy: 0.8824 - val_loss: 0.5428\n",
            "Epoch 1591/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4786 - val_accuracy: 0.8824 - val_loss: 0.5199\n",
            "Epoch 1592/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4791 - val_accuracy: 0.8824 - val_loss: 0.5231\n",
            "Epoch 1593/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5210\n",
            "Epoch 1594/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4791 - val_accuracy: 0.8824 - val_loss: 0.5266\n",
            "Epoch 1595/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5217\n",
            "Epoch 1596/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5263\n",
            "Epoch 1597/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4796 - val_accuracy: 0.8824 - val_loss: 0.5290\n",
            "Epoch 1598/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4794 - val_accuracy: 0.8824 - val_loss: 0.5175\n",
            "Epoch 1599/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5308\n",
            "Epoch 1600/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4794 - val_accuracy: 0.8824 - val_loss: 0.5332\n",
            "Epoch 1601/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5172\n",
            "Epoch 1602/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5237\n",
            "Epoch 1603/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5305\n",
            "Epoch 1604/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5141\n",
            "Epoch 1605/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5227\n",
            "Epoch 1606/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5391\n",
            "Epoch 1607/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5207\n",
            "Epoch 1608/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5208\n",
            "Epoch 1609/2000\n",
            "61/61 - 9s - 150ms/step - accuracy: 0.7803 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5150\n",
            "Epoch 1610/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4835 - val_accuracy: 0.8824 - val_loss: 0.5475\n",
            "Epoch 1611/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5382\n",
            "Epoch 1612/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5323\n",
            "Epoch 1613/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5263\n",
            "Epoch 1614/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5292\n",
            "Epoch 1615/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5170\n",
            "Epoch 1616/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5215\n",
            "Epoch 1617/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5219\n",
            "Epoch 1618/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4792 - val_accuracy: 0.8824 - val_loss: 0.5276\n",
            "Epoch 1619/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5228\n",
            "Epoch 1620/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5338\n",
            "Epoch 1621/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5172\n",
            "Epoch 1622/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5194\n",
            "Epoch 1623/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4790 - val_accuracy: 0.8824 - val_loss: 0.5128\n",
            "Epoch 1624/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5222\n",
            "Epoch 1625/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7836 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5166\n",
            "Epoch 1626/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7705 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5198\n",
            "Epoch 1627/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4791 - val_accuracy: 0.8824 - val_loss: 0.5170\n",
            "Epoch 1628/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7836 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5126\n",
            "Epoch 1629/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5121\n",
            "Epoch 1630/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5143\n",
            "Epoch 1631/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5130\n",
            "Epoch 1632/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5503\n",
            "Epoch 1633/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5225\n",
            "Epoch 1634/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7836 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5213\n",
            "Epoch 1635/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5181\n",
            "Epoch 1636/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4793 - val_accuracy: 0.8824 - val_loss: 0.5258\n",
            "Epoch 1637/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5205\n",
            "Epoch 1638/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5246\n",
            "Epoch 1639/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5274\n",
            "Epoch 1640/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5191\n",
            "Epoch 1641/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7639 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5245\n",
            "Epoch 1642/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5217\n",
            "Epoch 1643/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5222\n",
            "Epoch 1644/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5175\n",
            "Epoch 1645/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7869 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5150\n",
            "Epoch 1646/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5131\n",
            "Epoch 1647/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7836 - loss: 0.4796 - val_accuracy: 0.8824 - val_loss: 0.5223\n",
            "Epoch 1648/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5184\n",
            "Epoch 1649/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5242\n",
            "Epoch 1650/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5251\n",
            "Epoch 1651/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7836 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5103\n",
            "Epoch 1652/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5200\n",
            "Epoch 1653/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5279\n",
            "Epoch 1654/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5176\n",
            "Epoch 1655/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7639 - loss: 0.4796 - val_accuracy: 0.8824 - val_loss: 0.5249\n",
            "Epoch 1656/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5147\n",
            "Epoch 1657/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5205\n",
            "Epoch 1658/2000\n",
            "61/61 - 9s - 150ms/step - accuracy: 0.7803 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5223\n",
            "Epoch 1659/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5244\n",
            "Epoch 1660/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5278\n",
            "Epoch 1661/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5240\n",
            "Epoch 1662/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5241\n",
            "Epoch 1663/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5163\n",
            "Epoch 1664/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7672 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5117\n",
            "Epoch 1665/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5192\n",
            "Epoch 1666/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5193\n",
            "Epoch 1667/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5201\n",
            "Epoch 1668/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5260\n",
            "Epoch 1669/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4794 - val_accuracy: 0.8824 - val_loss: 0.5141\n",
            "Epoch 1670/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5135\n",
            "Epoch 1671/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5277\n",
            "Epoch 1672/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4790 - val_accuracy: 0.8824 - val_loss: 0.5251\n",
            "Epoch 1673/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4796 - val_accuracy: 0.8824 - val_loss: 0.5219\n",
            "Epoch 1674/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7869 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5419\n",
            "Epoch 1675/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7836 - loss: 0.4839 - val_accuracy: 0.8824 - val_loss: 0.5461\n",
            "Epoch 1676/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5162\n",
            "Epoch 1677/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5385\n",
            "Epoch 1678/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5218\n",
            "Epoch 1679/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5182\n",
            "Epoch 1680/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5218\n",
            "Epoch 1681/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4796 - val_accuracy: 0.8824 - val_loss: 0.5218\n",
            "Epoch 1682/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5309\n",
            "Epoch 1683/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5312\n",
            "Epoch 1684/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5282\n",
            "Epoch 1685/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5115\n",
            "Epoch 1686/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4794 - val_accuracy: 0.8824 - val_loss: 0.5233\n",
            "Epoch 1687/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5143\n",
            "Epoch 1688/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4796 - val_accuracy: 0.8824 - val_loss: 0.5235\n",
            "Epoch 1689/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4794 - val_accuracy: 0.8824 - val_loss: 0.5235\n",
            "Epoch 1690/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5180\n",
            "Epoch 1691/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5257\n",
            "Epoch 1692/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4791 - val_accuracy: 0.8824 - val_loss: 0.5151\n",
            "Epoch 1693/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4828 - val_accuracy: 0.8824 - val_loss: 0.5153\n",
            "Epoch 1694/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5164\n",
            "Epoch 1695/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5311\n",
            "Epoch 1696/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5424\n",
            "Epoch 1697/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5256\n",
            "Epoch 1698/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5257\n",
            "Epoch 1699/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5280\n",
            "Epoch 1700/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5226\n",
            "Epoch 1701/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4793 - val_accuracy: 0.8824 - val_loss: 0.5265\n",
            "Epoch 1702/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5321\n",
            "Epoch 1703/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5306\n",
            "Epoch 1704/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5197\n",
            "Epoch 1705/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5193\n",
            "Epoch 1706/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5187\n",
            "Epoch 1707/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7672 - loss: 0.4793 - val_accuracy: 0.8824 - val_loss: 0.5120\n",
            "Epoch 1708/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5225\n",
            "Epoch 1709/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5263\n",
            "Epoch 1710/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5372\n",
            "Epoch 1711/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5136\n",
            "Epoch 1712/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4793 - val_accuracy: 0.8824 - val_loss: 0.5287\n",
            "Epoch 1713/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5222\n",
            "Epoch 1714/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5153\n",
            "Epoch 1715/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5098\n",
            "Epoch 1716/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5292\n",
            "Epoch 1717/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5346\n",
            "Epoch 1718/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5202\n",
            "Epoch 1719/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5154\n",
            "Epoch 1720/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5225\n",
            "Epoch 1721/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5177\n",
            "Epoch 1722/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5247\n",
            "Epoch 1723/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7705 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5202\n",
            "Epoch 1724/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7836 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5277\n",
            "Epoch 1725/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4796 - val_accuracy: 0.8824 - val_loss: 0.5232\n",
            "Epoch 1726/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5176\n",
            "Epoch 1727/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5209\n",
            "Epoch 1728/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4793 - val_accuracy: 0.8824 - val_loss: 0.5215\n",
            "Epoch 1729/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4796 - val_accuracy: 0.8824 - val_loss: 0.5141\n",
            "Epoch 1730/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5144\n",
            "Epoch 1731/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5152\n",
            "Epoch 1732/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5309\n",
            "Epoch 1733/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5252\n",
            "Epoch 1734/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5247\n",
            "Epoch 1735/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4794 - val_accuracy: 0.8824 - val_loss: 0.5230\n",
            "Epoch 1736/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5301\n",
            "Epoch 1737/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5478\n",
            "Epoch 1738/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5230\n",
            "Epoch 1739/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5230\n",
            "Epoch 1740/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4794 - val_accuracy: 0.8824 - val_loss: 0.5232\n",
            "Epoch 1741/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4794 - val_accuracy: 0.8824 - val_loss: 0.5289\n",
            "Epoch 1742/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4793 - val_accuracy: 0.8824 - val_loss: 0.5152\n",
            "Epoch 1743/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5256\n",
            "Epoch 1744/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7672 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5145\n",
            "Epoch 1745/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5125\n",
            "Epoch 1746/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5229\n",
            "Epoch 1747/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4791 - val_accuracy: 0.8824 - val_loss: 0.5195\n",
            "Epoch 1748/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5249\n",
            "Epoch 1749/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7705 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5276\n",
            "Epoch 1750/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4791 - val_accuracy: 0.8824 - val_loss: 0.5173\n",
            "Epoch 1751/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7705 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5317\n",
            "Epoch 1752/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5326\n",
            "Epoch 1753/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5107\n",
            "Epoch 1754/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5112\n",
            "Epoch 1755/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7672 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5196\n",
            "Epoch 1756/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5207\n",
            "Epoch 1757/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5268\n",
            "Epoch 1758/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4785 - val_accuracy: 0.8824 - val_loss: 0.5155\n",
            "Epoch 1759/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5068\n",
            "Epoch 1760/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5244\n",
            "Epoch 1761/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5159\n",
            "Epoch 1762/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5306\n",
            "Epoch 1763/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4793 - val_accuracy: 0.8824 - val_loss: 0.5210\n",
            "Epoch 1764/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4794 - val_accuracy: 0.8824 - val_loss: 0.5310\n",
            "Epoch 1765/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4852 - val_accuracy: 0.8824 - val_loss: 0.5290\n",
            "Epoch 1766/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5350\n",
            "Epoch 1767/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5287\n",
            "Epoch 1768/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4791 - val_accuracy: 0.8824 - val_loss: 0.5257\n",
            "Epoch 1769/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5104\n",
            "Epoch 1770/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5193\n",
            "Epoch 1771/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5168\n",
            "Epoch 1772/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5104\n",
            "Epoch 1773/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4833 - val_accuracy: 0.8824 - val_loss: 0.5308\n",
            "Epoch 1774/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5245\n",
            "Epoch 1775/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5304\n",
            "Epoch 1776/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5156\n",
            "Epoch 1777/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5177\n",
            "Epoch 1778/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7672 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5229\n",
            "Epoch 1779/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4825 - val_accuracy: 0.8824 - val_loss: 0.5110\n",
            "Epoch 1780/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5139\n",
            "Epoch 1781/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7836 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5327\n",
            "Epoch 1782/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5237\n",
            "Epoch 1783/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5184\n",
            "Epoch 1784/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5384\n",
            "Epoch 1785/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5291\n",
            "Epoch 1786/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4790 - val_accuracy: 0.8824 - val_loss: 0.5150\n",
            "Epoch 1787/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7705 - loss: 0.4794 - val_accuracy: 0.8824 - val_loss: 0.5258\n",
            "Epoch 1788/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7705 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5175\n",
            "Epoch 1789/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4793 - val_accuracy: 0.8824 - val_loss: 0.5297\n",
            "Epoch 1790/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4842 - val_accuracy: 0.8824 - val_loss: 0.5465\n",
            "Epoch 1791/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5158\n",
            "Epoch 1792/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7705 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5276\n",
            "Epoch 1793/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5169\n",
            "Epoch 1794/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5284\n",
            "Epoch 1795/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5342\n",
            "Epoch 1796/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4796 - val_accuracy: 0.8824 - val_loss: 0.5262\n",
            "Epoch 1797/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7672 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5188\n",
            "Epoch 1798/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7836 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5096\n",
            "Epoch 1799/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4792 - val_accuracy: 0.8824 - val_loss: 0.5309\n",
            "Epoch 1800/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4832 - val_accuracy: 0.8824 - val_loss: 0.5336\n",
            "Epoch 1801/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5229\n",
            "Epoch 1802/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5438\n",
            "Epoch 1803/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5338\n",
            "Epoch 1804/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7705 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5222\n",
            "Epoch 1805/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5160\n",
            "Epoch 1806/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5183\n",
            "Epoch 1807/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5154\n",
            "Epoch 1808/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7836 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5302\n",
            "Epoch 1809/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5150\n",
            "Epoch 1810/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5165\n",
            "Epoch 1811/2000\n",
            "61/61 - 9s - 145ms/step - accuracy: 0.7803 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5225\n",
            "Epoch 1812/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5310\n",
            "Epoch 1813/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7672 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5271\n",
            "Epoch 1814/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4796 - val_accuracy: 0.8824 - val_loss: 0.5380\n",
            "Epoch 1815/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5126\n",
            "Epoch 1816/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5119\n",
            "Epoch 1817/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5241\n",
            "Epoch 1818/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5192\n",
            "Epoch 1819/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5334\n",
            "Epoch 1820/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5236\n",
            "Epoch 1821/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5208\n",
            "Epoch 1822/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5288\n",
            "Epoch 1823/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5128\n",
            "Epoch 1824/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7672 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5191\n",
            "Epoch 1825/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4822 - val_accuracy: 0.8824 - val_loss: 0.5063\n",
            "Epoch 1826/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5173\n",
            "Epoch 1827/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5208\n",
            "Epoch 1828/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5183\n",
            "Epoch 1829/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4791 - val_accuracy: 0.8824 - val_loss: 0.5235\n",
            "Epoch 1830/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5397\n",
            "Epoch 1831/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5310\n",
            "Epoch 1832/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4788 - val_accuracy: 0.8824 - val_loss: 0.5161\n",
            "Epoch 1833/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5272\n",
            "Epoch 1834/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5206\n",
            "Epoch 1835/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5165\n",
            "Epoch 1836/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4794 - val_accuracy: 0.8824 - val_loss: 0.5284\n",
            "Epoch 1837/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5201\n",
            "Epoch 1838/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5244\n",
            "Epoch 1839/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4786 - val_accuracy: 0.8824 - val_loss: 0.5266\n",
            "Epoch 1840/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5153\n",
            "Epoch 1841/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5193\n",
            "Epoch 1842/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4793 - val_accuracy: 0.8824 - val_loss: 0.5238\n",
            "Epoch 1843/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5175\n",
            "Epoch 1844/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5184\n",
            "Epoch 1845/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5223\n",
            "Epoch 1846/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4792 - val_accuracy: 0.8824 - val_loss: 0.5204\n",
            "Epoch 1847/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5148\n",
            "Epoch 1848/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4796 - val_accuracy: 0.8824 - val_loss: 0.5290\n",
            "Epoch 1849/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7705 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5288\n",
            "Epoch 1850/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4793 - val_accuracy: 0.8824 - val_loss: 0.5319\n",
            "Epoch 1851/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5286\n",
            "Epoch 1852/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5284\n",
            "Epoch 1853/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5257\n",
            "Epoch 1854/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4794 - val_accuracy: 0.8824 - val_loss: 0.5250\n",
            "Epoch 1855/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4794 - val_accuracy: 0.8824 - val_loss: 0.5173\n",
            "Epoch 1856/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5194\n",
            "Epoch 1857/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5219\n",
            "Epoch 1858/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5142\n",
            "Epoch 1859/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5327\n",
            "Epoch 1860/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4787 - val_accuracy: 0.8824 - val_loss: 0.5167\n",
            "Epoch 1861/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5233\n",
            "Epoch 1862/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4794 - val_accuracy: 0.8824 - val_loss: 0.5286\n",
            "Epoch 1863/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5189\n",
            "Epoch 1864/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5213\n",
            "Epoch 1865/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5228\n",
            "Epoch 1866/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5193\n",
            "Epoch 1867/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5238\n",
            "Epoch 1868/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5305\n",
            "Epoch 1869/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5183\n",
            "Epoch 1870/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4815 - val_accuracy: 0.8824 - val_loss: 0.5213\n",
            "Epoch 1871/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5194\n",
            "Epoch 1872/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5215\n",
            "Epoch 1873/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5133\n",
            "Epoch 1874/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5149\n",
            "Epoch 1875/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5229\n",
            "Epoch 1876/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7705 - loss: 0.4835 - val_accuracy: 0.8824 - val_loss: 0.5353\n",
            "Epoch 1877/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7672 - loss: 0.4826 - val_accuracy: 0.8824 - val_loss: 0.5233\n",
            "Epoch 1878/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4821 - val_accuracy: 0.8824 - val_loss: 0.5123\n",
            "Epoch 1879/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5397\n",
            "Epoch 1880/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5198\n",
            "Epoch 1881/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4793 - val_accuracy: 0.8824 - val_loss: 0.5223\n",
            "Epoch 1882/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5205\n",
            "Epoch 1883/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5126\n",
            "Epoch 1884/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4792 - val_accuracy: 0.8824 - val_loss: 0.5280\n",
            "Epoch 1885/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7705 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5181\n",
            "Epoch 1886/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5192\n",
            "Epoch 1887/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4790 - val_accuracy: 0.8824 - val_loss: 0.5137\n",
            "Epoch 1888/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5175\n",
            "Epoch 1889/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4792 - val_accuracy: 0.8824 - val_loss: 0.5174\n",
            "Epoch 1890/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5219\n",
            "Epoch 1891/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7836 - loss: 0.4830 - val_accuracy: 0.8824 - val_loss: 0.5211\n",
            "Epoch 1892/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4824 - val_accuracy: 0.8824 - val_loss: 0.5207\n",
            "Epoch 1893/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4817 - val_accuracy: 0.8824 - val_loss: 0.5161\n",
            "Epoch 1894/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5139\n",
            "Epoch 1895/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4791 - val_accuracy: 0.8824 - val_loss: 0.5276\n",
            "Epoch 1896/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5265\n",
            "Epoch 1897/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5232\n",
            "Epoch 1898/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5108\n",
            "Epoch 1899/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5306\n",
            "Epoch 1900/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7836 - loss: 0.4838 - val_accuracy: 0.8824 - val_loss: 0.5317\n",
            "Epoch 1901/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5267\n",
            "Epoch 1902/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5278\n",
            "Epoch 1903/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5073\n",
            "Epoch 1904/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4786 - val_accuracy: 0.8824 - val_loss: 0.5224\n",
            "Epoch 1905/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7836 - loss: 0.4814 - val_accuracy: 0.8824 - val_loss: 0.5482\n",
            "Epoch 1906/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4790 - val_accuracy: 0.8824 - val_loss: 0.5165\n",
            "Epoch 1907/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5370\n",
            "Epoch 1908/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5142\n",
            "Epoch 1909/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4791 - val_accuracy: 0.8824 - val_loss: 0.5187\n",
            "Epoch 1910/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5166\n",
            "Epoch 1911/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5145\n",
            "Epoch 1912/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4827 - val_accuracy: 0.8824 - val_loss: 0.5140\n",
            "Epoch 1913/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5198\n",
            "Epoch 1914/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5292\n",
            "Epoch 1915/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5184\n",
            "Epoch 1916/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5107\n",
            "Epoch 1917/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4819 - val_accuracy: 0.8824 - val_loss: 0.5189\n",
            "Epoch 1918/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4816 - val_accuracy: 0.8824 - val_loss: 0.5138\n",
            "Epoch 1919/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5200\n",
            "Epoch 1920/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4793 - val_accuracy: 0.8824 - val_loss: 0.5235\n",
            "Epoch 1921/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5240\n",
            "Epoch 1922/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7705 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5132\n",
            "Epoch 1923/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4807 - val_accuracy: 0.8824 - val_loss: 0.5079\n",
            "Epoch 1924/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5146\n",
            "Epoch 1925/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4791 - val_accuracy: 0.8824 - val_loss: 0.5259\n",
            "Epoch 1926/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5167\n",
            "Epoch 1927/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4796 - val_accuracy: 0.8824 - val_loss: 0.5164\n",
            "Epoch 1928/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5099\n",
            "Epoch 1929/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4791 - val_accuracy: 0.8824 - val_loss: 0.5269\n",
            "Epoch 1930/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5115\n",
            "Epoch 1931/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4788 - val_accuracy: 0.8824 - val_loss: 0.5213\n",
            "Epoch 1932/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5273\n",
            "Epoch 1933/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5241\n",
            "Epoch 1934/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5143\n",
            "Epoch 1935/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5119\n",
            "Epoch 1936/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5355\n",
            "Epoch 1937/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5323\n",
            "Epoch 1938/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5186\n",
            "Epoch 1939/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5221\n",
            "Epoch 1940/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5174\n",
            "Epoch 1941/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5199\n",
            "Epoch 1942/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4792 - val_accuracy: 0.8824 - val_loss: 0.5280\n",
            "Epoch 1943/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4791 - val_accuracy: 0.8824 - val_loss: 0.5145\n",
            "Epoch 1944/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4823 - val_accuracy: 0.8824 - val_loss: 0.5175\n",
            "Epoch 1945/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7738 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5257\n",
            "Epoch 1946/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5137\n",
            "Epoch 1947/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5259\n",
            "Epoch 1948/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4806 - val_accuracy: 0.8824 - val_loss: 0.5213\n",
            "Epoch 1949/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5200\n",
            "Epoch 1950/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4792 - val_accuracy: 0.8824 - val_loss: 0.5313\n",
            "Epoch 1951/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5194\n",
            "Epoch 1952/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7738 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5294\n",
            "Epoch 1953/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5223\n",
            "Epoch 1954/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5196\n",
            "Epoch 1955/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7705 - loss: 0.4796 - val_accuracy: 0.8824 - val_loss: 0.5258\n",
            "Epoch 1956/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4792 - val_accuracy: 0.8824 - val_loss: 0.5199\n",
            "Epoch 1957/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4811 - val_accuracy: 0.8824 - val_loss: 0.5344\n",
            "Epoch 1958/2000\n",
            "61/61 - 9s - 150ms/step - accuracy: 0.7770 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5338\n",
            "Epoch 1959/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5271\n",
            "Epoch 1960/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5169\n",
            "Epoch 1961/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5173\n",
            "Epoch 1962/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5214\n",
            "Epoch 1963/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5223\n",
            "Epoch 1964/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4794 - val_accuracy: 0.8824 - val_loss: 0.5167\n",
            "Epoch 1965/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4799 - val_accuracy: 0.8824 - val_loss: 0.5192\n",
            "Epoch 1966/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5293\n",
            "Epoch 1967/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4813 - val_accuracy: 0.8824 - val_loss: 0.5343\n",
            "Epoch 1968/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5396\n",
            "Epoch 1969/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5154\n",
            "Epoch 1970/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7770 - loss: 0.4797 - val_accuracy: 0.8824 - val_loss: 0.5308\n",
            "Epoch 1971/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4810 - val_accuracy: 0.8824 - val_loss: 0.5144\n",
            "Epoch 1972/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4793 - val_accuracy: 0.8824 - val_loss: 0.5187\n",
            "Epoch 1973/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4788 - val_accuracy: 0.8824 - val_loss: 0.5195\n",
            "Epoch 1974/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5196\n",
            "Epoch 1975/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4820 - val_accuracy: 0.8824 - val_loss: 0.5351\n",
            "Epoch 1976/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7836 - loss: 0.4818 - val_accuracy: 0.8824 - val_loss: 0.5313\n",
            "Epoch 1977/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4795 - val_accuracy: 0.8824 - val_loss: 0.5234\n",
            "Epoch 1978/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4809 - val_accuracy: 0.8824 - val_loss: 0.5118\n",
            "Epoch 1979/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5090\n",
            "Epoch 1980/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7770 - loss: 0.4808 - val_accuracy: 0.8824 - val_loss: 0.5445\n",
            "Epoch 1981/2000\n",
            "61/61 - 9s - 146ms/step - accuracy: 0.7803 - loss: 0.4791 - val_accuracy: 0.8824 - val_loss: 0.5226\n",
            "Epoch 1982/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4793 - val_accuracy: 0.8824 - val_loss: 0.5143\n",
            "Epoch 1983/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5217\n",
            "Epoch 1984/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4801 - val_accuracy: 0.8824 - val_loss: 0.5105\n",
            "Epoch 1985/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5185\n",
            "Epoch 1986/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4846 - val_accuracy: 0.8824 - val_loss: 0.5195\n",
            "Epoch 1987/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5176\n",
            "Epoch 1988/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7672 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5215\n",
            "Epoch 1989/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5255\n",
            "Epoch 1990/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4790 - val_accuracy: 0.8824 - val_loss: 0.5154\n",
            "Epoch 1991/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4800 - val_accuracy: 0.8824 - val_loss: 0.5170\n",
            "Epoch 1992/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4805 - val_accuracy: 0.8824 - val_loss: 0.5251\n",
            "Epoch 1993/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7803 - loss: 0.4834 - val_accuracy: 0.8824 - val_loss: 0.5122\n",
            "Epoch 1994/2000\n",
            "61/61 - 9s - 147ms/step - accuracy: 0.7705 - loss: 0.4804 - val_accuracy: 0.8824 - val_loss: 0.5110\n",
            "Epoch 1995/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4789 - val_accuracy: 0.8824 - val_loss: 0.5290\n",
            "Epoch 1996/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4802 - val_accuracy: 0.8824 - val_loss: 0.5390\n",
            "Epoch 1997/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7738 - loss: 0.4798 - val_accuracy: 0.8824 - val_loss: 0.5355\n",
            "Epoch 1998/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7803 - loss: 0.4787 - val_accuracy: 0.8824 - val_loss: 0.5203\n",
            "Epoch 1999/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7705 - loss: 0.4803 - val_accuracy: 0.8824 - val_loss: 0.5243\n",
            "Epoch 2000/2000\n",
            "61/61 - 9s - 148ms/step - accuracy: 0.7770 - loss: 0.4812 - val_accuracy: 0.8824 - val_loss: 0.5178\n",
            "CPU times: user 1d 11h 29min 50s, sys: 17h 39min 29s, total: 2d 5h 9min 19s\n",
            "Wall time: 10h 10min 17s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x42dab0c80>"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-04T11:42:06.641965Z",
          "start_time": "2025-03-04T11:42:06.580336Z"
        },
        "id": "c3bccd33d7f137fe",
        "outputId": "171c497e-5861-4e96-e7f5-df139284877c"
      },
      "cell_type": "code",
      "source": [
        "# Plot error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(model.history.history['loss'])\n",
        "plt.plot(model.history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "id": "c3bccd33d7f137fe",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-04T11:42:12.206813Z",
          "start_time": "2025-03-04T11:42:12.192184Z"
        },
        "id": "85c98c3b9e85ef25",
        "outputId": "ca90447c-cbb4-49bf-9d38-36b280349817"
      },
      "cell_type": "code",
      "source": [
        "# Display the model summary\n",
        "model.summary()"
      ],
      "id": "85c98c3b9e85ef25",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_20\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_20\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " text_input           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " embedding_20         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m100\u001b[0m)    \u001b[38;5;34m3,052,200\u001b[0m  text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
              "\n",
              " flatten_20           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51200\u001b[0m)               \u001b[38;5;34m0\u001b[0m  embedding_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
              " (\u001b[38;5;33mFlatten\u001b[0m)                                                             \n",
              "\n",
              " dense_124 (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)       \u001b[38;5;34m104,859,6\u001b[0m  flatten_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " dense_125 (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        \u001b[38;5;34m2,098,176\u001b[0m  dense_124[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " dense_126 (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)           \u001b[38;5;34m524,800\u001b[0m  dense_125[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " dense_127 (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           \u001b[38;5;34m131,328\u001b[0m  dense_126[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " dense_128 (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m32,896\u001b[0m  dense_127[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " dense_129 (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)              \u001b[38;5;34m8,256\u001b[0m  dense_128[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " dense_130 (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)              \u001b[38;5;34m2,080\u001b[0m  dense_129[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " dense_131 (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                \u001b[38;5;34m528\u001b[0m  dense_130[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " dense_132 (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                 \u001b[38;5;34m136\u001b[0m  dense_131[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " func_rating_input    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " dense_133 (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                  \u001b[38;5;34m36\u001b[0m  dense_132[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " dense_134 (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                 \u001b[38;5;34m64\u001b[0m  func_rating_inpu \n",
              "\n",
              " concatenate_20       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  dense_133[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  \n",
              " (\u001b[38;5;33mConcatenate\u001b[0m)                                       dense_134[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " output (\u001b[38;5;33mDense\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                  \u001b[38;5;34m74\u001b[0m  concatenate_20[\u001b[38;5;34m0\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
              "\n",
              " text_input           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " embedding_20         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    <span style=\"color: #00af00; text-decoration-color: #00af00\">3,052,200</span>  text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
              "\n",
              " flatten_20           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51200</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  embedding_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                                                             \n",
              "\n",
              " dense_124 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">104,859,6</span>  flatten_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " dense_125 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span>  dense_124[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " dense_126 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span>  dense_125[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " dense_127 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span>  dense_126[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " dense_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span>  dense_127[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " dense_129 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span>  dense_128[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " dense_130 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span>  dense_129[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " dense_131 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span>  dense_130[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " dense_132 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span>  dense_131[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " func_rating_input    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " dense_133 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>  dense_132[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " dense_134 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>  func_rating_inpu \n",
              "\n",
              " concatenate_20       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_133[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       dense_134[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>  concatenate_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m332,130,668\u001b[0m (1.24 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">332,130,668</span> (1.24 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m110,710,222\u001b[0m (422.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,710,222</span> (422.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m221,420,446\u001b[0m (844.65 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">221,420,446</span> (844.65 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-04T11:42:16.280380Z",
          "start_time": "2025-03-04T11:42:15.930175Z"
        },
        "id": "29ae4877bf163a68",
        "outputId": "adb59677-07aa-4972-b8ae-af5f4368412b"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Predict probabilities for the test set\n",
        "# Assume X_test_text and X_test_func_rating are your test datasets prepared similarly to your training datasets\n",
        "predictions = model.predict({\"text_input\": X_text, \"func_rating_input\": X_func_rating})\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Since y_test is in one-hot encoded format, convert it back to class labels for evaluation\n",
        "true_classes = np.argmax(y_one_hot, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(true_classes, predicted_classes)\n",
        "print(report)"
      ],
      "id": "29ae4877bf163a68",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.94      0.87       236\n",
            "           1       0.70      0.35      0.47        86\n",
            "\n",
            "    accuracy                           0.79       322\n",
            "   macro avg       0.75      0.65      0.67       322\n",
            "weighted avg       0.77      0.79      0.76       322\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-04T11:42:17.100927Z",
          "start_time": "2025-03-04T11:42:17.098685Z"
        },
        "id": "54fe09cb41f084ee",
        "outputId": "2a073e85-fc2a-4e28-fb25-671d028d7639"
      },
      "cell_type": "code",
      "source": [
        "67/(215+67)"
      ],
      "id": "54fe09cb41f084ee",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.2375886524822695"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-04T13:10:42.646952Z",
          "start_time": "2025-03-04T13:10:42.510515Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "75568bc1ecbc480e",
        "outputId": "357e739c-ec6c-4597-97fa-3ec3f6f05b64"
      },
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi\n",
        "\n",
        "hf_username = \"Bhairavee37\"  # Replace with your Hugging Face username\n",
        "repo_name = \"my-tf-nn-model-v2\"  # Change this as needed\n",
        "repo_id = f\"{hf_username}/{repo_name}\"\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "# Create the repository\n",
        "api.create_repo(repo_id=repo_id, exist_ok=True)  # exist_ok=True prevents errors if the repo already exists\n",
        "\n",
        "print(f\"Repository created: https://huggingface.co/{repo_id}\")"
      ],
      "id": "75568bc1ecbc480e",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "HfHubHTTPError",
          "evalue": "401 Client Error: Unauthorized for url: https://huggingface.co/api/repos/create (Request ID: Root=1-67c7850b-6869574b62ceee83093bcfcd;e5289f08-02d6-4b76-9da9-1c3bd67d4605)\n\nInvalid username or password.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/repos/create",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cebfe03a96dd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Create the repository\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_repo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# exist_ok=True prevents errors if the repo already exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Repository created: https://huggingface.co/{repo_id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mcreate_repo\u001b[0;34m(self, repo_id, token, private, repo_type, exist_ok, resource_group_id, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[0m\n\u001b[1;32m   3479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3480\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3481\u001b[0;31m             \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3482\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3483\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexist_ok\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m409\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;31m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;31m# as well (request id and/or server error message)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHfHubHTTPError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/repos/create (Request ID: Root=1-67c7850b-6869574b62ceee83093bcfcd;e5289f08-02d6-4b76-9da9-1c3bd67d4605)\n\nInvalid username or password."
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-04T13:13:26.350658Z",
          "start_time": "2025-03-04T13:11:48.966240Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "d87e0296549dd1ac",
        "outputId": "4a238a61-e19f-494f-ddf6-1cf1c5c35aa4"
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "from huggingface_hub import HfApi\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Define save directory\n",
        "model_dir = \"./saved_model\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# Save the model\n",
        "model_path = os.path.join(model_dir, \"model.keras\")\n",
        "model.save(model_path)\n",
        "\n",
        "# Save the tokenizer as a pickle file\n",
        "tokenizer_path = os.path.join(model_dir, \"tokenizer.pkl\")\n",
        "with open(tokenizer_path, \"wb\") as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "# Upload model and tokenizer to Hugging Face\n",
        "repo_id = f\"{hf_username}/{repo_name}\"  # Change as needed\n",
        "api = HfApi()\n",
        "\n",
        "api.upload_file(path_or_fileobj=model_path, path_in_repo=\"model.keras\", repo_id=repo_id)\n",
        "api.upload_file(path_or_fileobj=tokenizer_path, path_in_repo=\"tokenizer.pkl\", repo_id=repo_id)\n",
        "\n",
        "print(f\"Model and tokenizer successfully pushed to: https://huggingface.co/{repo_id}\")"
      ],
      "id": "d87e0296549dd1ac",
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4081877f8429>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model.keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Save the tokenizer as a pickle file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-04T11:46:04.484205Z",
          "start_time": "2025-03-04T11:45:43.057458Z"
        },
        "colab": {
          "referenced_widgets": [
            "c0cce7005acb49f1b5cb4fe0ce7f2c2b"
          ]
        },
        "id": "75e54dd376f4f799",
        "outputId": "1fa52b6f-09bf-4cdd-f712-589c47958624"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# Set Keras backend to JAX (Optional, only needed if you want to experiment with JAX backend)\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
        "\n",
        "# Define repo ID and model filename\n",
        "# repo_id = \"eagle0504/my-tf-nn-model\" # we already defined it above\n",
        "filename = \"model.keras\"  # Ensure this matches what was uploaded\n",
        "\n",
        "# Download the model\n",
        "model_path = hf_hub_download(repo_id=repo_id, filename=filename)\n",
        "\n",
        "# Load the Keras model\n",
        "new_model = keras.models.load_model(model_path)\n",
        "\n",
        "print(\"Model loaded successfully!\")"
      ],
      "id": "75e54dd376f4f799",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "model.keras:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0cce7005acb49f1b5cb4fe0ce7f2c2b"
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully!\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-04T11:46:04.499355Z",
          "start_time": "2025-03-04T11:46:04.488336Z"
        },
        "id": "7c7ebeb76ccddbc4",
        "outputId": "51e3c700-0a50-467b-c170-44b48fffccbb"
      },
      "cell_type": "code",
      "source": [
        "new_model.summary()"
      ],
      "id": "7c7ebeb76ccddbc4",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_20\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_20\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " text_input           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " embedding_20         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m100\u001b[0m)    \u001b[38;5;34m3,052,200\u001b[0m  text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
              "\n",
              " flatten_20           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51200\u001b[0m)               \u001b[38;5;34m0\u001b[0m  embedding_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
              " (\u001b[38;5;33mFlatten\u001b[0m)                                                             \n",
              "\n",
              " dense_124 (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)       \u001b[38;5;34m104,859,6\u001b[0m  flatten_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " dense_125 (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        \u001b[38;5;34m2,098,176\u001b[0m  dense_124[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " dense_126 (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)           \u001b[38;5;34m524,800\u001b[0m  dense_125[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " dense_127 (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           \u001b[38;5;34m131,328\u001b[0m  dense_126[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " dense_128 (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m32,896\u001b[0m  dense_127[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " dense_129 (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)              \u001b[38;5;34m8,256\u001b[0m  dense_128[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " dense_130 (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)              \u001b[38;5;34m2,080\u001b[0m  dense_129[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " dense_131 (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                \u001b[38;5;34m528\u001b[0m  dense_130[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " dense_132 (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                 \u001b[38;5;34m136\u001b[0m  dense_131[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " func_rating_input    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " dense_133 (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                  \u001b[38;5;34m36\u001b[0m  dense_132[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " dense_134 (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                 \u001b[38;5;34m64\u001b[0m  func_rating_inpu \n",
              "\n",
              " concatenate_20       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  dense_133[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  \n",
              " (\u001b[38;5;33mConcatenate\u001b[0m)                                       dense_134[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " output (\u001b[38;5;33mDense\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                  \u001b[38;5;34m74\u001b[0m  concatenate_20[\u001b[38;5;34m0\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
              "\n",
              " text_input           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " embedding_20         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    <span style=\"color: #00af00; text-decoration-color: #00af00\">3,052,200</span>  text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
              "\n",
              " flatten_20           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51200</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  embedding_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                                                             \n",
              "\n",
              " dense_124 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">104,859,6</span>  flatten_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " dense_125 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span>  dense_124[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " dense_126 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span>  dense_125[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " dense_127 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span>  dense_126[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " dense_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span>  dense_127[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " dense_129 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span>  dense_128[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " dense_130 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span>  dense_129[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " dense_131 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span>  dense_130[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " dense_132 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span>  dense_131[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " func_rating_input    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " dense_133 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>  dense_132[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " dense_134 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>  func_rating_inpu \n",
              "\n",
              " concatenate_20       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_133[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       dense_134[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>  concatenate_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m332,130,668\u001b[0m (1.24 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">332,130,668</span> (1.24 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m110,710,222\u001b[0m (422.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,710,222</span> (422.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m221,420,446\u001b[0m (844.65 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">221,420,446</span> (844.65 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-04T14:13:04.843488Z",
          "start_time": "2025-03-04T14:12:48.648598Z"
        },
        "colab": {
          "referenced_widgets": [
            "d2c96df12d3e4dd1967d2a6f06e486d1"
          ]
        },
        "id": "c685eaa160c3b8c",
        "outputId": "933ca622-3f46-44d6-f768-26503381e668"
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from huggingface_hub import hf_hub_download\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Define repo details\n",
        "repo_id = f\"{hf_username}/{repo_name}\"\n",
        "\n",
        "# Download model\n",
        "model_path = hf_hub_download(repo_id=repo_id, filename=\"model.keras\")\n",
        "new_model = keras.models.load_model(model_path)\n",
        "\n",
        "# Load a transformer-based tokenizer (e.g., BertTokenizer)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "print(\"Model and tokenizer loaded successfully!\")\n",
        "\n",
        "# Sample test data\n",
        "test_texts = [\n",
        "    \"How to improve focus and concentration?\",\n",
        "    \"What are the side effects of lack of sleep?\",\n",
        "]\n",
        "\n",
        "# Preprocess test data using the Hugging Face tokenizer\n",
        "max_length = new_model.input_shape[0][1]  # Get max_length from model input shape\n",
        "X_text_test = tokenizer(\n",
        "    test_texts,\n",
        "    max_length=max_length,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    return_tensors=\"tf\"\n",
        ")\n",
        "\n",
        "# Dummy numeric input (func_rating)\n",
        "X_func_test = np.array([5, 4]).reshape(-1, 1)\n",
        "\n",
        "# Make predictions\n",
        "predictions = new_model.predict({\"text_input\": X_text_test[\"input_ids\"], \"func_rating_input\": X_func_test})\n",
        "\n",
        "# Display results\n",
        "for i, text in enumerate(test_texts):\n",
        "    print(f\"Prompt: {text}\")\n",
        "    print(f\"Predicted Rating: {predictions[i][0]:.2f}\")\n",
        "    print(\"-\" * 50)"
      ],
      "id": "c685eaa160c3b8c",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "model.keras:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2c96df12d3e4dd1967d2a6f06e486d1"
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and tokenizer loaded successfully!\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "Prompt: How to improve focus and concentration?\n",
            "Predicted Rating: 0.29\n",
            "--------------------------------------------------\n",
            "Prompt: What are the side effects of lack of sleep?\n",
            "Predicted Rating: 0.40\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "e17e36c4a4a52aa3"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [],
      "id": "e17e36c4a4a52aa3"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}